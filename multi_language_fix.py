#!/usr/bin/env python3
"""
Multi-Language Fix for TTS System
‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏£‡∏∞‡∏ö‡∏ö multi-language detection ‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡∏•‡∏≤‡∏ß‡πÑ‡∏î‡πâ
"""

import re
import asyncio
import logging
from typing import List, Tuple, Dict, Any
from pathlib import Path

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MultiLanguageDetector:
    """‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤"""
    
    def __init__(self):
        # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
        self.language_patterns = {
            'lao': {
                'pattern': r'[\u0E80-\u0EFF]+(?:\s+[\u0E80-\u0EFF]+)*',
                'name': 'Lao',
                'voice': 'lo-LA-KeomanyNeural'
            },
            'thai': {
                'pattern': r'[\u0E00-\u0E7F]+(?:\s+[\u0E00-\u0E7F]+)*',
                'name': 'Thai', 
                'voice': 'th-TH-PremwadeeNeural'
            },
            'english': {
                'pattern': r'[a-zA-Z]+(?:\s+[a-zA-Z]+)*',
                'name': 'English',
                'voice': 'en-US-AriaNeural'
            },
            'chinese': {
                'pattern': r'[\u4E00-\u9FFF]+(?:\s+[\u4E00-\u9FFF]+)*',
                'name': 'Chinese',
                'voice': 'zh-CN-XiaoxiaoNeural'
            },
            'japanese': {
                'pattern': r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]+(?:\s+[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]+)*',
                'name': 'Japanese',
                'voice': 'ja-JP-NanamiNeural'
            },
            'numbers': {
                'pattern': r'\d+(?:\.\d+)?',
                'name': 'Numbers',
                'voice': None  # ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á
            },
            'punctuation': {
                'pattern': r'[^\w\s\u0E00-\u0E7F\u0E80-\u0EFF\u4E00-\u9FFF\u3040-\u309F\u30A0-\u30FF]',
                'name': 'Punctuation',
                'voice': None  # ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á
            }
        }
    
    def detect_language_segments(self, text: str) -> List[Tuple[str, str, str]]:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å
            
        Returns:
            List[Tuple[str, str, str]]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°, ‡∏†‡∏≤‡∏©‡∏≤, ‡πÄ‡∏™‡∏µ‡∏¢‡∏á)
        """
        if not text.strip():
            return []
        
        segments = []
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á regex pattern ‡∏£‡∏ß‡∏°
        all_patterns = []
        for lang_code, lang_info in self.language_patterns.items():
            pattern = f'(?P<{lang_code}>{lang_info["pattern"]})'
            all_patterns.append(pattern)
        
        combined_pattern = '|'.join(all_patterns)
        
        # ‡∏´‡∏≤ matches ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        matches = list(re.finditer(combined_pattern, text, re.UNICODE))
        
        if not matches:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÜ ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            return [(text, 'unknown', 'lo-LA-KeomanyNeural')]
        
        # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
        matches.sort(key=lambda x: x.start())
        
        # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ
        current_pos = 0
        
        for match in matches:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÜ (‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á, ‡∏Ø‡∏•‡∏Ø)
            if match.start() > current_pos:
                gap_text = text[current_pos:match.start()]
                if gap_text.strip():
                    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á
                    surrounding_lang = self._determine_surrounding_language(matches, current_pos)
                    segments.append((gap_text, surrounding_lang, self._get_voice_for_language(surrounding_lang)))
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
            for lang_code, lang_info in self.language_patterns.items():
                if match.group(lang_code):
                    segments.append((match.group(lang_code), lang_info['name'], lang_info['voice']))
                    break
            
            current_pos = match.end()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
        if current_pos < len(text):
            remaining_text = text[current_pos:]
            if remaining_text.strip():
                surrounding_lang = self._determine_surrounding_language(matches, current_pos)
                segments.append((remaining_text, surrounding_lang, self._get_voice_for_language(surrounding_lang)))
        
        # ‡∏£‡∏ß‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
        merged_segments = self._merge_adjacent_segments(segments)
        
        return merged_segments
    
    def _determine_surrounding_language(self, matches: List, position: int) -> str:
        """‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á"""
        # ‡∏´‡∏≤ match ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        closest_match = None
        min_distance = float('inf')
        
        for match in matches:
            distance = min(abs(match.start() - position), abs(match.end() - position))
            if distance < min_distance:
                min_distance = distance
                closest_match = match
        
        if closest_match:
            # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≤‡∏° match ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
            for lang_code, lang_info in self.language_patterns.items():
                if closest_match.group(lang_code):
                    return lang_info['name']
        
        return 'Lao'  # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    
    def _get_voice_for_language(self, language: str) -> str:
        """‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤"""
        voice_mapping = {
            'Lao': 'lo-LA-KeomanyNeural',
            'Thai': 'th-TH-PremwadeeNeural',
            'English': 'en-US-AriaNeural',
            'Chinese': 'zh-CN-XiaoxiaoNeural',
            'Japanese': 'ja-JP-NanamiNeural',
            'Numbers': 'lo-LA-KeomanyNeural',  # ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            'Punctuation': 'lo-LA-KeomanyNeural',  # ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            'unknown': 'lo-LA-KeomanyNeural'
        }
        
        return voice_mapping.get(language, 'lo-LA-KeomanyNeural')
    
    def _merge_adjacent_segments(self, segments: List[Tuple[str, str, str]]) -> List[Tuple[str, str, str]]:
        """‡∏£‡∏ß‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô"""
        if not segments:
            return []
        
        merged = []
        current_text = segments[0][0]
        current_lang = segments[0][1]
        current_voice = segments[0][2]
        
        for text, lang, voice in segments[1:]:
            # ‡∏£‡∏ß‡∏°‡∏ñ‡πâ‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
            if lang == current_lang and voice == current_voice:
                current_text += text
            else:
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                merged.append((current_text, current_lang, current_voice))
                # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏°‡πà
                current_text = text
                current_lang = lang
                current_voice = voice
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        merged.append((current_text, current_lang, current_voice))
        
        return merged

def create_enhanced_tts_core():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á TTS Core ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß"""
    
    # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå tts_rvc_core.py
    core_file = Path("tts_rvc_core.py")
    if not core_file.exists():
        logger.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå tts_rvc_core.py")
        return False
    
    # ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
    with open(core_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô detect_language_segments
    old_detect_function = '''    def detect_language_segments(self, text: str) -> List[Tuple[str, str]]:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å
            
        Returns:
            List[Tuple[str, str]]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°, ‡∏†‡∏≤‡∏©‡∏≤)
        """
        segments = []
        
        # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤
        patterns = {
            'english': r'[a-zA-Z]+(?:\s+[a-zA-Z]+)*',
            'lao': r'[\u0E80-\u0EFF]+(?:\s+[\u0E80-\u0EFF]+)*',
            'thai': r'[\u0E00-\u0E7F]+(?:\s+[\u0E00-\u0E7F]+)*',
            'chinese': r'[\u4E00-\u9FFF]+(?:\s+[\u4E00-\u9FFF]+)*',
            'japanese': r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]+(?:\s+[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]+)*',
            'numbers': r'\d+(?:\.\d+)?',
            'punctuation': r'[^\w\s\u0E00-\u0E7F\u0E80-\u0EFF\u4E00-\u9FFF\u3040-\u309F\u30A0-\u30FF]'
        }
        
        # ‡∏£‡∏ß‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        all_patterns = '|'.join(f'({pattern})' for pattern in patterns.values())
        
        # ‡∏´‡∏≤ matches ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        matches = list(re.finditer(all_patterns, text, re.UNICODE))
        
        if not matches:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÜ ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            return [(text, 'unknown')]
        
        # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
        matches.sort(key=lambda x: x.start())
        
        # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ
        current_pos = 0
        
        for match in matches:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÜ (‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á, ‡∏Ø‡∏•‡∏Ø)
            if match.start() > current_pos:
                gap_text = text[current_pos:match.start()]
                if gap_text.strip():
                    segments.append((gap_text, 'unknown'))
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
            for i, (lang, pattern) in enumerate(patterns.items()):
                if match.group(i + 1):
                    segments.append((match.group(i + 1), lang))
                    break
            
            current_pos = match.end()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
        if current_pos < len(text):
            remaining_text = text[current_pos:]
            if remaining_text.strip():
                segments.append((remaining_text, 'unknown'))
        
        return segments'''
    
    new_detect_function = '''    def detect_language_segments(self, text: str) -> List[Tuple[str, str, str]]:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å
            
        Returns:
            List[Tuple[str, str, str]]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°, ‡∏†‡∏≤‡∏©‡∏≤, ‡πÄ‡∏™‡∏µ‡∏¢‡∏á)
        """
        if not text.strip():
            return []
        
        segments = []
        
        # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
        language_patterns = {
            'lao': {
                'pattern': r'[\u0E80-\u0EFF]+(?:\s+[\u0E80-\u0EFF]+)*',
                'name': 'Lao',
                'voice': 'lo-LA-KeomanyNeural'
            },
            'thai': {
                'pattern': r'[\u0E00-\u0E7F]+(?:\s+[\u0E00-\u0E7F]+)*',
                'name': 'Thai', 
                'voice': 'th-TH-PremwadeeNeural'
            },
            'english': {
                'pattern': r'[a-zA-Z]+(?:\s+[a-zA-Z]+)*',
                'name': 'English',
                'voice': 'en-US-AriaNeural'
            },
            'chinese': {
                'pattern': r'[\u4E00-\u9FFF]+(?:\s+[\u4E00-\u9FFF]+)*',
                'name': 'Chinese',
                'voice': 'zh-CN-XiaoxiaoNeural'
            },
            'japanese': {
                'pattern': r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]+(?:\s+[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]+)*',
                'name': 'Japanese',
                'voice': 'ja-JP-NanamiNeural'
            },
            'numbers': {
                'pattern': r'\d+(?:\.\d+)?',
                'name': 'Numbers',
                'voice': 'lo-LA-KeomanyNeural'
            },
            'punctuation': {
                'pattern': r'[^\w\s\u0E00-\u0E7F\u0E80-\u0EFF\u4E00-\u9FFF\u3040-\u309F\u30A0-\u30FF]',
                'name': 'Punctuation',
                'voice': 'lo-LA-KeomanyNeural'
            }
        }
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á regex pattern ‡∏£‡∏ß‡∏°
        all_patterns = []
        for lang_code, lang_info in language_patterns.items():
            pattern = f'(?P<{lang_code}>{lang_info["pattern"]})'
            all_patterns.append(pattern)
        
        combined_pattern = '|'.join(all_patterns)
        
        # ‡∏´‡∏≤ matches ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        matches = list(re.finditer(combined_pattern, text, re.UNICODE))
        
        if not matches:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÜ ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            return [(text, 'Lao', 'lo-LA-KeomanyNeural')]
        
        # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
        matches.sort(key=lambda x: x.start())
        
        # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ
        current_pos = 0
        
        for match in matches:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÜ (‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á, ‡∏Ø‡∏•‡∏Ø)
            if match.start() > current_pos:
                gap_text = text[current_pos:match.start()]
                if gap_text.strip():
                    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á
                    surrounding_lang = self._determine_surrounding_language(matches, current_pos)
                    segments.append((gap_text, surrounding_lang, self._get_voice_for_language(surrounding_lang)))
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
            for lang_code, lang_info in language_patterns.items():
                if match.group(lang_code):
                    segments.append((match.group(lang_code), lang_info['name'], lang_info['voice']))
                    break
            
            current_pos = match.end()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
        if current_pos < len(text):
            remaining_text = text[current_pos:]
            if remaining_text.strip():
                surrounding_lang = self._determine_surrounding_language(matches, current_pos)
                segments.append((remaining_text, surrounding_lang, self._get_voice_for_language(surrounding_lang)))
        
        # ‡∏£‡∏ß‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
        merged_segments = self._merge_adjacent_segments(segments)
        
        return merged_segments
    
    def _determine_surrounding_language(self, matches: List, position: int) -> str:
        """‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á"""
        # ‡∏´‡∏≤ match ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        closest_match = None
        min_distance = float('inf')
        
        for match in matches:
            distance = min(abs(match.start() - position), abs(match.end() - position))
            if distance < min_distance:
                min_distance = distance
                closest_match = match
        
        if closest_match:
            # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≤‡∏° match ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
            language_patterns = {
                'lao': 'Lao',
                'thai': 'Thai',
                'english': 'English',
                'chinese': 'Chinese',
                'japanese': 'Japanese',
                'numbers': 'Numbers',
                'punctuation': 'Punctuation'
            }
            
            for lang_code, lang_name in language_patterns.items():
                if closest_match.group(lang_code):
                    return lang_name
        
        return 'Lao'  # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    
    def _get_voice_for_language(self, language: str) -> str:
        """‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤"""
        voice_mapping = {
            'Lao': 'lo-LA-KeomanyNeural',
            'Thai': 'th-TH-PremwadeeNeural',
            'English': 'en-US-AriaNeural',
            'Chinese': 'zh-CN-XiaoxiaoNeural',
            'Japanese': 'ja-JP-NanamiNeural',
            'Numbers': 'lo-LA-KeomanyNeural',
            'Punctuation': 'lo-LA-KeomanyNeural',
            'unknown': 'lo-LA-KeomanyNeural'
        }
        
        return voice_mapping.get(language, 'lo-LA-KeomanyNeural')
    
    def _merge_adjacent_segments(self, segments: List[Tuple[str, str, str]]) -> List[Tuple[str, str, str]]:
        """‡∏£‡∏ß‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô"""
        if not segments:
            return []
        
        merged = []
        current_text = segments[0][0]
        current_lang = segments[0][1]
        current_voice = segments[0][2]
        
        for text, lang, voice in segments[1:]:
            # ‡∏£‡∏ß‡∏°‡∏ñ‡πâ‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
            if lang == current_lang and voice == current_voice:
                current_text += text
            else:
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                merged.append((current_text, current_lang, current_voice))
                # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏°‡πà
                current_text = text
                current_lang = lang
                current_voice = voice
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        merged.append((current_text, current_lang, current_voice))
        
        return merged'''
    
    # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô
    if old_detect_function in content:
        content = content.replace(old_detect_function, new_detect_function)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà
        backup_file = Path("tts_rvc_core_backup.py")
        if not backup_file.exists():
            with open(backup_file, 'w', encoding='utf-8') as f:
                f.write(content.replace(new_detect_function, old_detect_function))
            logger.info(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå backup: {backup_file}")
        
        with open(core_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info("‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå tts_rvc_core.py ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        return True
    else:
        logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô detect_language_segments ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå")
        return False

def update_generate_tts_function():
    """‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô generate_tts ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö multi-language ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà"""
    
    core_file = Path("tts_rvc_core.py")
    if not core_file.exists():
        logger.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå tts_rvc_core.py")
        return False
    
    with open(core_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á multi-language processing ‡πÉ‡∏ô generate_tts
    old_multi_lang_section = '''        if enable_multi_language:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤
            segments = self.detect_language_segments(text)
            
            if len(segments) == 1:
                # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
                return await self._generate_single_tts(text, voice, speed, pitch)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
            audio_segments = []
            for segment_text, segment_language in segments:
                if not segment_text.strip():
                    continue
                
                # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
                segment_voice = self.get_voice_for_language(segment_language, voice)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
                segment_audio = await self._generate_single_tts(
                    segment_text, segment_voice, speed, pitch
                )
                audio_segments.append(segment_audio)
            
            # ‡∏£‡∏ß‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            if audio_segments:
                return self._combine_audio_segments(audio_segments)
            else:
                raise Exception("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ")'''
    
    new_multi_lang_section = '''        if enable_multi_language:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
            segments = self.detect_language_segments(text)
            
            if len(segments) == 1:
                # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
                return await self._generate_single_tts(text, voice, speed, pitch)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
            audio_segments = []
            for segment_text, segment_language, segment_voice in segments:
                if not segment_text.strip():
                    continue
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
                segment_audio = await self._generate_single_tts(
                    segment_text, segment_voice, speed, pitch
                )
                audio_segments.append(segment_audio)
            
            # ‡∏£‡∏ß‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            if audio_segments:
                return self._combine_audio_segments(audio_segments)
            else:
                raise Exception("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ")'''
    
    # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏ß‡∏ô
    if old_multi_lang_section in content:
        content = content.replace(old_multi_lang_section, new_multi_lang_section)
        
        with open(core_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info("‚úÖ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô generate_tts ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        return True
    else:
        logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡πà‡∏ß‡∏ô multi-language processing ‡πÉ‡∏ô generate_tts")
        return False

def create_test_script():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ó‡∏î‡∏™‡∏≠‡∏ö multi-language"""
    
    test_script = '''#!/usr/bin/env python3
"""
Test Multi-Language TTS
‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö multi-language TTS
"""

import asyncio
import sys
import os

# ‡πÄ‡∏û‡∏¥‡πà‡∏° path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from tts_rvc_core import TTSRVCCore

async def test_multi_language():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö multi-language"""
    print("üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö Multi-Language TTS...")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á core instance
    core = TTSRVCCore()
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤
    test_cases = [
        {
            "text": "‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ Hello ‡∫ó‡∫∏‡∫Å‡∫Ñ‡∫ª‡∫ô! How are you? ‡∫Ç‡ªâ‡∫≠‡∫ç‡∫î‡∫µ",
            "description": "‡∏•‡∏≤‡∏ß + ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© + ‡∏•‡∏≤‡∏ß"
        },
        {
            "text": "Hello ‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ ‡∫ó‡∫∏‡∫Å‡∫Ñ‡∫ª‡∫ô! How are you today?",
            "description": "‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© + ‡∏•‡∏≤‡∏ß + ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©"
        },
        {
            "text": "‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ ‡∫ó‡∫∏‡∫Å‡∫Ñ‡∫ª‡∫ô! ‡∫Ç‡ªâ‡∫≠‡∫ç‡∫ä‡∫∑‡ªà‡∫ß‡ªà‡∫≤ John ‡ªÅ‡∫•‡∫∞ ‡∫Ç‡ªâ‡∫≠‡∫ç‡∫°‡∫≤‡∫à‡∫≤‡∫Å America",
            "description": "‡∏•‡∏≤‡∏ß + ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© + ‡∏•‡∏≤‡∏ß"
        },
        {
            "text": "Welcome to ‡∫•‡∫≤‡∫ß! ‡∫õ‡∫∞‡ªÄ‡∫ó‡∫î‡∫ó‡∫µ‡ªà‡∫™‡∫ß‡∫ç‡∫á‡∫≤‡∫°",
            "description": "‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© + ‡∏•‡∏≤‡∏ß"
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\\nüìù ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà {i}: {test_case['description']}")
        print(f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {test_case['text']}")
        
        try:
            # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤
            segments = core.detect_language_segments(test_case['text'])
            print(f"üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤: {len(segments)} ‡∏™‡πà‡∏ß‡∏ô")
            for j, (text, lang, voice) in enumerate(segments):
                print(f"  ‡∏™‡πà‡∏ß‡∏ô {j+1}: '{text}' -> {lang} ({voice})")
            
            # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            print("üéµ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")
            audio_data = await core.generate_tts(
                test_case['text'], 
                'lo-LA-KeomanyNeural', 
                enable_multi_language=True
            )
            print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(audio_data)} bytes")
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            output_file = f"test_multi_lang_{i}.wav"
            with open(output_file, 'wb') as f:
                f.write(audio_data)
            print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå: {output_file}")
            
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
    
    print("\\nüéâ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")

if __name__ == "__main__":
    asyncio.run(test_multi_language())
'''
    
    with open("test_multi_language.py", 'w', encoding='utf-8') as f:
        f.write(test_script)
    
    logger.info("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå test_multi_language.py")

def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å"""
    print("üîß ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏£‡∏∞‡∏ö‡∏ö Multi-Language Detection...")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á enhanced TTS core
    if create_enhanced_tts_core():
        print("‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô detect_language_segments ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    else:
        print("‚ùå ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô detect_language_segments ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        return
    
    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô generate_tts
    if update_generate_tts_function():
        print("‚úÖ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô generate_tts ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    else:
        print("‚ùå ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô generate_tts ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        return
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    create_test_script()
    
    print("\nüéâ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏£‡∏∞‡∏ö‡∏ö Multi-Language ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
    print("üìù ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà:")
    print("  - ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏≤‡∏ß")
    print("  - ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤")
    print("  - ‡∏£‡∏ß‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô")
    print("  - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ú‡∏™‡∏°‡∏ú‡∏™‡∏≤‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤")
    
    print("\nüß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö:")
    print("  python test_multi_language.py")

if __name__ == "__main__":
    main() 
#!/usr/bin/env python3
"""
üéØ TTS-RVC Core System - ‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏£‡∏ß‡∏° TTS ‡πÅ‡∏•‡∏∞ RVC
‡∏£‡∏ß‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
"""
import os
import sys
import asyncio
from pathlib import Path
import logging
from typing import Optional, Dict, Any, List, Union

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("TTS_RVC_CORE")

class TTSRVCCore:
    """‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö TTS ‡πÅ‡∏•‡∏∞ RVC"""
    
    def __init__(self, models_dir: str = "logs", temp_dir: str = "storage/temp", 
                 device: str = None, use_gpu: bool = True, gpu_id: int = 0):
        """
        ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö TTS-RVC
        
        Args:
            models_dir: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• RVC
            temp_dir: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
            device: ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• (cpu, cuda:0, cuda:1, ...) - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô None ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î use_gpu ‡πÅ‡∏•‡∏∞ gpu_id
            use_gpu: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô GPU ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            gpu_id: ID ‡∏Ç‡∏≠‡∏á GPU ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (0, 1, 2, ...)
        """
        self.models_dir = Path(models_dir)
        self.temp_dir = Path(temp_dir)
        self.temp_dir.mkdir(parents=True, exist_ok=True)
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GPU
        self.setup_device(device, use_gpu, gpu_id)
        
        # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö
        self.tts_available = False
        self.rvc_available = False
        self.rvc_instance = None
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏∞‡∏ö‡∏ö
        self._initialize_systems()
        
        logger.info(f"TTS-RVC Core initialized - TTS: {self.tts_available}, RVC: {self.rvc_available}, Device: {self.device}")
    
    def setup_device(self, device: str = None, use_gpu: bool = True, gpu_id: int = 0):
        """
        ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        
        Args:
            device: ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• (cpu, cuda:0, cuda:1, ...) - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô None ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î use_gpu ‡πÅ‡∏•‡∏∞ gpu_id
            use_gpu: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô GPU ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            gpu_id: ID ‡∏Ç‡∏≠‡∏á GPU ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (0, 1, 2, ...)
        """
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU
        self.gpu_available = False
        self.gpu_info = None
        
        try:
            import torch
            self.gpu_available = torch.cuda.is_available()
            
            if self.gpu_available:
                gpu_count = torch.cuda.device_count()
                
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• GPU
                self.gpu_info = []
                for i in range(gpu_count):
                    name = torch.cuda.get_device_name(i)
                    memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
                    self.gpu_info.append({
                        "id": i,
                        "name": name,
                        "memory": memory
                    })
                logger.info(f"Found {gpu_count} GPUs: {', '.join(g['name'] for g in self.gpu_info)}")
        except ImportError:
            logger.warning("PyTorch not available, using CPU only")
        except Exception as e:
            logger.warning(f"Error detecting GPU: {e}")
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î device
        if device is not None:
            # ‡πÉ‡∏ä‡πâ device ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
            self.device = device
        elif not use_gpu or not self.gpu_available:
            # ‡πÉ‡∏ä‡πâ CPU
            self.device = "cpu"
        else:
            # ‡πÉ‡∏ä‡πâ GPU ‡∏ï‡∏≤‡∏° ID
            try:
                if gpu_id < len(self.gpu_info):
                    self.device = f"cuda:{gpu_id}"
                else:
                    logger.warning(f"GPU ID {gpu_id} not found, using GPU 0 instead")
                    self.device = "cuda:0"
            except:
                self.device = "cuda:0"
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°
        if "cuda" in self.device and self.gpu_available:
            gpu_id_num = int(self.device.split(":")[-1])
            os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id_num)
            logger.info(f"Using GPU {gpu_id_num}: {self.get_gpu_name(gpu_id_num)}")
        else:
            os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
            self.device = "cpu"
            logger.info("Using CPU")
    
    def get_gpu_name(self, gpu_id: int = 0) -> str:
        """‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á GPU ‡∏ï‡∏≤‡∏° ID"""
        if self.gpu_info and gpu_id < len(self.gpu_info):
            return self.gpu_info[gpu_id]["name"]
        return "Unknown"
    
    def _initialize_systems(self):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö TTS ‡πÅ‡∏•‡∏∞ RVC"""
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô TTS
        try:
            import edge_tts
            self.tts_available = True
            logger.info("‚úÖ Edge TTS system loaded")
        except ImportError:
            logger.warning("‚ö†Ô∏è Edge TTS not available")
        
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô RVC
        try:
            from rvc_api import RVCConverter
            self.rvc_instance = RVCConverter(device=self.device, models_dir=self.models_dir)
            self.rvc_available = True
            logger.info(f"‚úÖ RVC system loaded on {self.device}")
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è RVC system not available: {e}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è RVC system initialization failed: {e}")
    
    def get_system_status(self) -> Dict[str, Any]:
        """‡∏î‡∏∂‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡∏∞‡∏ö‡∏ö"""
        return {
            "tts_available": self.tts_available,
            "rvc_available": self.rvc_available,
            "device": self.device,
            "gpu_name": self.get_gpu_name(int(self.device.split(':')[-1])) if "cuda" in self.device and self.gpu_available else "CPU",
            "rvc_models_count": len(self.get_available_rvc_models()) if self.rvc_available else 0
        }
    
    async def test_edge_tts_connection(self, voice: str = "th-TH-PremwadeeNeural") -> bool:
        """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Edge TTS"""
        try:
            import edge_tts
            
            # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡πÜ
            test_text = "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ"
            communicate = edge_tts.Communicate(text=test_text, voice=voice)
            
            audio_data = b""
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    audio_data += chunk["data"]
            
            if audio_data:
                logger.info(f"Edge TTS connection test successful with voice: {voice}")
                return True
            else:
                logger.error(f"Edge TTS connection test failed - no audio received for voice: {voice}")
                return False
                
        except Exception as e:
            logger.error(f"Edge TTS connection test failed: {e}")
            return False
    
    async def get_available_edge_voices(self) -> List[str]:
        """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ voice ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô Edge TTS"""
        try:
            import edge_tts
            voices = await edge_tts.list_voices()
            return [voice["ShortName"] for voice in voices]
        except Exception as e:
            logger.error(f"Error getting Edge TTS voices: {e}")
            return []
    
    def get_available_rvc_models(self) -> List[str]:
        """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏• RVC ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà"""
        if not self.rvc_available:
            return []
        
        try:
            return self.rvc_instance.get_available_models()
        except Exception as e:
            logger.error(f"Error getting RVC models: {e}")
            return []
    
    async def generate_tts(self, text: str, voice: str, speed: float = 1.0, 
                          pitch: str = "+0Hz") -> bytes:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ Edge TTS
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á
            voice: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (‡πÄ‡∏ä‡πà‡∏ô th-TH-PremwadeeNeural)
            speed: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î (0.5-2.0)
            pitch: ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡πÄ‡∏ä‡πà‡∏ô +0Hz, +10Hz)
            
        Returns:
            bytes: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö bytes
        """
        if not self.tts_available:
            raise Exception("TTS system not available")
        
        try:
            import edge_tts
            
            # Log ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå
            logger.info(f"Generating TTS with text='{text[:30]}...', voice='{voice}', speed={speed}, pitch={pitch}")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            if not text or not text.strip():
                raise Exception("Text is empty or contains only whitespace")
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° - ‡∏•‡∏ö‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤
            cleaned_text = text.strip()
            # ‡∏•‡∏ö‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            cleaned_text = ''.join(char for char in cleaned_text if ord(char) >= 32 or char in '\n\r\t')
            
            if not cleaned_text:
                raise Exception("Text is empty after cleaning")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö voice
            if not voice or not voice.strip():
                raise Exception("Voice is not specified")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ voice ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            try:
                available_voices = await self.get_available_edge_voices()
                if voice not in available_voices:
                    logger.warning(f"Voice '{voice}' not found in available voices. Available voices: {available_voices[:5]}...")
                    # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ voice ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
                    fallback_voice = "th-TH-PremwadeeNeural"
                    if fallback_voice in available_voices:
                        logger.info(f"Using fallback voice: {fallback_voice}")
                        voice = fallback_voice
                    else:
                        raise Exception(f"Voice '{voice}' not available and no fallback voice found")
            except Exception as voice_error:
                logger.warning(f"Could not verify voice availability: {voice_error}")
                # ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö voice
            
            # ‡∏õ‡∏£‡∏±‡∏ö rate ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö speed
            if speed != 1.0:
                rate = f"{speed:+.0%}"
            else:
                rate = "+0%"
            
            logger.info(f"Using cleaned text: '{cleaned_text[:50]}...'")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á Communicate object
            communicate = edge_tts.Communicate(
                text=cleaned_text,
                voice=voice,
                rate=rate,
                pitch=pitch
            )
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            audio_data = b""
            chunk_count = 0
            
            try:
                async for chunk in communicate.stream():
                    if chunk["type"] == "audio":
                        audio_data += chunk["data"]
                        chunk_count += 1
                    elif chunk["type"] == "WordBoundary":
                        logger.debug(f"Word boundary: {chunk}")
                    elif chunk["type"] == "SentenceBoundary":
                        logger.debug(f"Sentence boundary: {chunk}")
            except Exception as stream_error:
                logger.error(f"Error during streaming: {stream_error}")
                raise Exception(f"Streaming error: {str(stream_error)}")
            
            logger.info(f"Received {chunk_count} audio chunks")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if not audio_data:
                logger.error("No audio was received. Please verify that your parameters are correct.")
                raise Exception("No audio was received. Please verify that your parameters are correct.")
            
            logger.info(f"TTS generated: {len(audio_data)} bytes")
            return audio_data
            
        except Exception as e:
            logger.error(f"TTS generation failed: {e}")
            raise Exception(f"TTS generation failed: {str(e)}")
    
    def convert_voice(self, audio_data: bytes, model_name: str, 
                     transpose: int = 0, index_ratio: float = 0.75,
                     f0_method: str = "rmvpe") -> bytes:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ RVC
        
        Args:
            audio_data: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á
            model_name: ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏• RVC
            transpose: ‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏±‡∏ö pitch (-12 ‡∏ñ‡∏∂‡∏á 12)
            index_ratio: ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô index (0.0-1.0)
            f0_method: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì f0
            
        Returns:
            bytes: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡πâ‡∏ß
        """
        if not self.rvc_available:
            raise Exception("RVC system not available")
        
        try:
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå input
            temp_input = self.temp_dir / f"rvc_input_{os.getpid()}.wav"
            temp_output = self.temp_dir / f"rvc_output_{os.getpid()}.wav"
            
            with open(temp_input, "wb") as f:
                f.write(audio_data)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            result_path = self.rvc_instance.convert_voice(
                input_path=str(temp_input),
                output_path=str(temp_output),
                model_name=model_name,
                transpose=transpose,
                index_ratio=index_ratio,
                f0_method=f0_method
            )
            
            # ‡∏≠‡πà‡∏≤‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            with open(result_path, "rb") as f:
                converted_audio = f.read()
            
            # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
            temp_input.unlink(missing_ok=True)
            temp_output.unlink(missing_ok=True)
            if Path(result_path) != temp_output:
                Path(result_path).unlink(missing_ok=True)
            
            logger.info(f"Voice conversion completed: {len(converted_audio)} bytes")
            return converted_audio
            
        except Exception as e:
            logger.error(f"Voice conversion failed: {e}")
            raise Exception(f"Voice conversion failed: {str(e)}")
    
    async def process_unified(self, text: str, tts_voice: str, 
                            enable_rvc: bool = False, rvc_model: str = None,
                            tts_speed: float = 1.0, tts_pitch: str = "+0Hz",
                            rvc_transpose: int = 0, rvc_index_ratio: float = 0.75,
                            rvc_f0_method: str = "rmvpe") -> Dict[str, Any]:
        """
        ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏ß‡∏° TTS + RVC ‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á
            tts_voice: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á TTS
            enable_rvc: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ RVC ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            rvc_model: ‡πÇ‡∏°‡πÄ‡∏î‡∏• RVC (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ)
            tts_speed: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß TTS
            tts_pitch: ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á TTS
            rvc_transpose: ‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏±‡∏ö pitch RVC
            rvc_index_ratio: ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô index RVC
            rvc_f0_method: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ f0 RVC
            
        Returns:
            Dict: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
        """
        result = {
            "success": False,
            "audio_data": None,
            "processing_steps": [],
            "error": None,
            "stats": {}
        }
        
        try:
            # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á TTS
            logger.info("Step 1: Generating TTS...")
            tts_audio = await self.generate_tts(text, tts_voice, tts_speed, tts_pitch)
            result["processing_steps"].append("tts_generation")
            result["stats"]["tts_audio_size"] = len(tts_audio)
            
            final_audio = tts_audio
            
            # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ RVC (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ)
            if enable_rvc and rvc_model:
                logger.info(f"Step 2: Checking RVC model '{rvc_model}'...")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ RVC system ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                if not self.rvc_available:
                    logger.warning("RVC system not available")
                    result["processing_steps"].append("rvc_unavailable")
                    result["error"] = "RVC system not available"
                else:
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    available_models = self.get_available_rvc_models()
                    if rvc_model not in available_models:
                        logger.warning(f"RVC model '{rvc_model}' not found. Available models: {available_models}")
                        result["processing_steps"].append("rvc_model_not_found")
                        result["error"] = f"RVC model '{rvc_model}' not found"
                    else:
                        logger.info(f"Step 2: Applying voice conversion with model '{rvc_model}'...")
                        try:
                            converted_audio = self.convert_voice(
                                tts_audio, rvc_model, rvc_transpose, 
                                rvc_index_ratio, rvc_f0_method
                            )
                            final_audio = converted_audio
                            result["processing_steps"].append("voice_conversion")
                            result["stats"]["rvc_audio_size"] = len(converted_audio)
                            logger.info(f"Voice conversion successful: {len(converted_audio)} bytes")
                        except Exception as rvc_error:
                            logger.error(f"Voice conversion failed: {rvc_error}")
                            result["processing_steps"].append("rvc_failed")
                            result["error"] = f"Voice conversion failed: {str(rvc_error)}"
                            # ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á TTS ‡πÄ‡∏î‡∏¥‡∏°
            elif enable_rvc and not rvc_model:
                logger.warning("RVC enabled but no model specified")
                result["processing_steps"].append("rvc_no_model")
                result["error"] = "RVC enabled but no model specified"
            
            # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            result.update({
                "success": True,
                "audio_data": final_audio,
                "stats": {
                    **result["stats"],
                    "text_length": len(text),
                    "final_audio_size": len(final_audio),
                    "voice_conversion_applied": "voice_conversion" in result["processing_steps"],
                    "device": self.device
                }
            })
            
            logger.info(f"Unified processing completed: {result['processing_steps']}")
            return result
            
        except Exception as e:
            logger.error(f"Unified processing failed: {e}")
            result.update({
                "success": False,
                "error": str(e)
            })
            return result
    
    def smart_chunk_text(self, text: str, max_chunk_size: int = 8000) -> List[str]:
        """
        ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ç‡∏â‡∏•‡∏≤‡∏î ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á TTS
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á
            max_chunk_size: ‡∏Ç‡∏ô‡∏≤‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
            
        Returns:
            List[str]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß
        """
        if len(text) <= max_chunk_size:
            return [text]
        
        chunks = []
        current_chunk = ""
        
        # ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
        sentences = text.replace(".", ".\\n").replace("!", "!\\n").replace("?", "?\\n").split("\\n")
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡πâ‡∏ß‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î
            if len(current_chunk) + len(sentence) + 1 <= max_chunk_size:
                if current_chunk:
                    current_chunk += " " + sentence
                else:
                    current_chunk = sentence
            else:
                # ‡πÄ‡∏Å‡πá‡∏ö chunk ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                if current_chunk:
                    chunks.append(current_chunk)
                
                # ‡πÄ‡∏£‡∏¥‡πà‡∏° chunk ‡πÉ‡∏´‡∏°‡πà
                if len(sentence) <= max_chunk_size:
                    current_chunk = sentence
                else:
                    # ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥
                    words = sentence.split()
                    temp_chunk = ""
                    for word in words:
                        if len(temp_chunk) + len(word) + 1 <= max_chunk_size:
                            if temp_chunk:
                                temp_chunk += " " + word
                            else:
                                temp_chunk = word
                        else:
                            if temp_chunk:
                                chunks.append(temp_chunk)
                            temp_chunk = word
                    current_chunk = temp_chunk
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° chunk ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        if current_chunk:
            chunks.append(current_chunk)
        
        logger.info(f"Text chunked into {len(chunks)} parts")
        return chunks
    
    async def process_long_text(self, text: str, tts_voice: str,
                               max_chunk_size: int = 8000, **kwargs) -> Dict[str, Any]:
        """
        ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á chunk
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß
            tts_voice: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á TTS
            max_chunk_size: ‡∏Ç‡∏ô‡∏≤‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ chunk
            **kwargs: ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö process_unified
            
        Returns:
            Dict: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏£‡∏ß‡∏°‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å chunk
        """
        # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        chunks = self.smart_chunk_text(text, max_chunk_size)
        
        if len(chunks) == 1:
            # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô ‡πÉ‡∏ä‡πâ process_unified ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
            return await self.process_unified(text, tts_voice, **kwargs)
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• chunk ‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß
        all_audio_data = []
        all_processing_steps = []
        total_stats = {
            "chunks_count": len(chunks),
            "total_text_length": len(text),
            "chunk_sizes": [len(chunk) for chunk in chunks]
        }
        
        for i, chunk in enumerate(chunks):
            logger.info(f"Processing chunk {i+1}/{len(chunks)}: {len(chunk)} chars")
            
            chunk_result = await self.process_unified(chunk, tts_voice, **kwargs)
            
            if chunk_result["success"]:
                all_audio_data.append(chunk_result["audio_data"])
                all_processing_steps.extend([f"chunk_{i+1}_{step}" for step in chunk_result["processing_steps"]])
            else:
                logger.error(f"Chunk {i+1} failed: {chunk_result.get('error')}")
                return {
                    "success": False,
                    "error": f"Chunk {i+1} processing failed: {chunk_result.get('error')}",
                    "chunks_processed": i
                }
            
            # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á chunk
            await asyncio.sleep(0.1)
        
        # ‡∏£‡∏ß‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        try:
            combined_audio = b"".join(all_audio_data)
            
            return {
                "success": True,
                "audio_data": combined_audio,
                "processing_steps": all_processing_steps,
                "stats": {
                    **total_stats,
                    "final_audio_size": len(combined_audio),
                    "chunks_processed": len(chunks),
                    "processing_method": "multi_chunk",
                    "device": self.device
                }
            }
        except Exception as e:
            logger.error(f"Audio combination failed: {e}")
            return {
                "success": False,
                "error": f"Audio combination failed: {str(e)}",
                "chunks_processed": len(chunks)
            }
    
    def cleanup_temp_files(self):
        """‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤"""
        try:
            import time
            current_time = time.time()
            cutoff_time = current_time - 3600  # 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
            
            for file_path in self.temp_dir.glob("*"):
                if file_path.is_file() and file_path.stat().st_mtime < cutoff_time:
                    file_path.unlink(missing_ok=True)
            
            logger.info("Temp files cleaned")
        except Exception as e:
            logger.error(f"Cleanup error: {e}")
            
    def change_device(self, new_device: str = None, use_gpu: bool = None, gpu_id: int = None):
        """
        ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        
        Args:
            new_device: ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÉ‡∏´‡∏°‡πà (cpu, cuda:0, cuda:1, ...)
            use_gpu: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô GPU ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            gpu_id: ID ‡∏Ç‡∏≠‡∏á GPU ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (0, 1, 2, ...)
        
        Returns:
            bool: True ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à, False ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
        """
        try:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡∏°‡πà ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°
            if use_gpu is None:
                use_gpu = "cuda" in self.device
            if gpu_id is None and "cuda:" in self.device:
                gpu_id = int(self.device.split(":")[-1])
            elif gpu_id is None:
                gpu_id = 0
                
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å device ‡πÄ‡∏î‡∏¥‡∏°
            old_device = self.device
            
            # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ device ‡πÉ‡∏´‡∏°‡πà
            self.setup_device(new_device, use_gpu, gpu_id)
            
            # ‡∏ñ‡πâ‡∏≤ device ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà
            if old_device != self.device:
                logger.info(f"Device changed from {old_device} to {self.device}, reinitializing systems")
                self._initialize_systems()
                return True
            
            return False
        except Exception as e:
            logger.error(f"Error changing device: {e}")
            return False

# ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
SUPPORTED_VOICES = {
    "th-TH-PremwadeeNeural": {"name": "Premwadee (Thai Female)", "gender": "Female", "language": "Thai"},
    "th-TH-NiranNeural": {"name": "Niran (Thai Male)", "gender": "Male", "language": "Thai"},
    "th-TH-NiwatNeural": {"name": "Niwat (Thai Male)", "gender": "Male", "language": "Thai"},
    "lo-LA-ChanthavongNeural": {"name": "Chanthavong (Lao Male)", "gender": "Male", "language": "Lao"},
    "lo-LA-KeomanyNeural": {"name": "Keomany (Lao Female)", "gender": "Female", "language": "Lao"},
    "en-US-AriaNeural": {"name": "Aria (US Female)", "gender": "Female", "language": "English"},
    "en-US-GuyNeural": {"name": "Guy (US Male)", "gender": "Male", "language": "English"},
    "en-US-JennyNeural": {"name": "Jenny (US Female)", "gender": "Female", "language": "English"},
    "ja-JP-NanamiNeural": {"name": "Nanami (Japanese Female)", "gender": "Female", "language": "Japanese"},
    "zh-CN-XiaoxiaoNeural": {"name": "Xiaoxiao (Chinese Female)", "gender": "Female", "language": "Chinese"}
}

# Helper functions
def create_core_instance(**kwargs) -> TTSRVCCore:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á instance ‡∏Ç‡∏≠‡∏á TTS-RVC Core"""
    return TTSRVCCore(**kwargs)

def get_supported_voices() -> Dict[str, Dict[str, str]]:
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö"""
    return SUPPORTED_VOICES

# Test function
async def test_core_system():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö Core"""
    print("üîß Testing TTS-RVC Core System...")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU
    try:
        import torch
        if torch.cuda.is_available():
            device = f"cuda:{torch.cuda.current_device()}"
            print(f"Found GPU: {torch.cuda.get_device_name(0)}")
        else:
            device = "cpu"
            print("No GPU available, using CPU")
    except ImportError:
        device = "cpu"
        print("PyTorch not available, using CPU")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á instance
    core = create_core_instance(device=device)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
    status = core.get_system_status()
    print(f"‚úÖ System Status: {status}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö TTS
    if status["tts_available"]:
        print("üéµ Testing TTS...")
        try:
            test_text = "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö TTS"
            audio_data = await core.generate_tts(test_text, "th-TH-PremwadeeNeural")
            print(f"‚úÖ TTS Test: {len(audio_data)} bytes generated")
        except Exception as e:
            print(f"‚ùå TTS Test failed: {e}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö RVC (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•)
    if status["rvc_available"] and status["rvc_models_count"] > 0:
        print("üé≠ Testing RVC...")
        try:
            # ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å TTS ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
            if 'audio_data' in locals():
                model_name = core.get_available_rvc_models()[0]
                converted = core.convert_voice(audio_data, model_name)
                print(f"‚úÖ RVC Test: {len(converted)} bytes converted using {model_name}")
        except Exception as e:
            print(f"‚ùå RVC Test failed: {e}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏ß‡∏°
    print("üöÄ Testing Unified Processing...")
    try:
        result = await core.process_unified(
            text="‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏ß‡∏° TTS ‡πÅ‡∏•‡∏∞ RVC",
            tts_voice="th-TH-PremwadeeNeural",
            enable_rvc=status["rvc_available"] and status["rvc_models_count"] > 0,
            rvc_model=core.get_available_rvc_models()[0] if status["rvc_models_count"] > 0 else None
        )
        print(f"‚úÖ Unified Test: {result['success']}, Steps: {result['processing_steps']}")
    except Exception as e:
        print(f"‚ùå Unified Test failed: {e}")
    
    print("üéâ Core system testing completed!")

if __name__ == "__main__":
    # ‡∏£‡∏±‡∏ô test
    asyncio.run(test_core_system())

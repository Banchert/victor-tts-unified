#!/usr/bin/env python3
"""
üéØ TTS-RVC Core System - ‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏£‡∏ß‡∏° TTS ‡πÅ‡∏•‡∏∞ RVC
‡∏£‡∏ß‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
"""
import os
import sys
import asyncio
import re
from pathlib import Path
import logging
from typing import Optional, Dict, Any, List, Union, Tuple
from model_utils import safe_model_processing, normalize_model_name

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("TTS_RVC_CORE")

class TTSRVCCore:
    """‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö TTS ‡πÅ‡∏•‡∏∞ RVC"""
    
    def __init__(self, models_dir: str = "logs", temp_dir: str = "storage/temp", 
                 device: str = None, use_gpu: bool = True, gpu_id: int = 0,
                 performance_config: Dict[str, Any] = None):
        """
        ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö TTS-RVC
        
        Args:
            models_dir: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• RVC
            temp_dir: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
            device: ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• (cpu, cuda:0, cuda:1, ...) - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô None ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î use_gpu ‡πÅ‡∏•‡∏∞ gpu_id
            use_gpu: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô GPU ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            gpu_id: ID ‡∏Ç‡∏≠‡∏á GPU ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (0, 1, 2, ...)
            performance_config: ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        """
        self.models_dir = Path(models_dir)
        self.temp_dir = Path(temp_dir)
        self.temp_dir.mkdir(parents=True, exist_ok=True)
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        self.performance_config = self._load_performance_config(performance_config)
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GPU
        self.setup_device(device, use_gpu, gpu_id)
        
        # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö
        self.tts_available = False
        self.rvc_available = False
        self.rvc_instance = None
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏∞‡∏ö‡∏ö
        self._initialize_systems()
        
        logger.info(f"TTS-RVC Core initialized - TTS: {self.tts_available}, RVC: {self.rvc_available}, Device: {self.device}")
        logger.info(f"Performance config: TTS concurrent={self.performance_config.get('tts_max_concurrent', 1)}, RVC batch={self.performance_config.get('rvc_batch_size', 1)}")
    
    def _load_performance_config(self, config: Dict[str, Any] = None) -> Dict[str, Any]:
        """‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û"""
        if config:
            return config
        
        # ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå
        config_file = Path("config/performance_config.json")
        if config_file.exists():
            try:
                import json
                with open(config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"Failed to load performance config: {e}")
        
        # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        return {
            "tts_batch_size": 1,
            "tts_chunk_size": 5000,
            "tts_max_concurrent": 1,
            "rvc_batch_size": 1,
            "rvc_use_half_precision": True,
            "rvc_cache_models": True,
            "audio_sample_rate": 44100,
            "audio_chunk_duration": 10,
            "audio_use_soxr": True,
            "use_multiprocessing": True,
            "max_workers": 1,
            "memory_limit_gb": 2,
            "gpu_memory_fraction": 0.8,
            "gpu_allow_growth": True,
            "gpu_mixed_precision": True
        }
    
    def setup_device(self, device: str = None, use_gpu: bool = True, gpu_id: int = 0):
        """
        ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        
        Args:
            device: ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• (cpu, cuda:0, cuda:1, ...) - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô None ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î use_gpu ‡πÅ‡∏•‡∏∞ gpu_id
            use_gpu: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô GPU ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            gpu_id: ID ‡∏Ç‡∏≠‡∏á GPU ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (0, 1, 2, ...)
        """
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU
        self.gpu_available = False
        self.gpu_info = None
        
        try:
            import torch
            self.gpu_available = torch.cuda.is_available()
            
            if self.gpu_available:
                gpu_count = torch.cuda.device_count()
                
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• GPU
                self.gpu_info = []
                for i in range(gpu_count):
                    name = torch.cuda.get_device_name(i)
                    memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
                    self.gpu_info.append({
                        "id": i,
                        "name": name,
                        "memory": memory
                    })
                logger.info(f"Found {gpu_count} GPUs: {', '.join(g['name'] for g in self.gpu_info)}")
        except ImportError:
            logger.warning("PyTorch not available, using CPU only")
        except Exception as e:
            logger.warning(f"Error detecting GPU: {e}")
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î device
        if device is not None:
            # ‡πÉ‡∏ä‡πâ device ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
            self.device = device
        elif not use_gpu or not self.gpu_available:
            # ‡πÉ‡∏ä‡πâ CPU
            self.device = "cpu"
        else:
            # ‡πÉ‡∏ä‡πâ GPU ‡∏ï‡∏≤‡∏° ID
            try:
                if gpu_id < len(self.gpu_info):
                    self.device = f"cuda:{gpu_id}"
                else:
                    logger.warning(f"GPU ID {gpu_id} not found, using GPU 0 instead")
                    self.device = "cuda:0"
            except:
                self.device = "cuda:0"
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°
        if "cuda" in self.device and self.gpu_available:
            gpu_id_num = int(self.device.split(":")[-1])
            os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id_num)
            logger.info(f"Using GPU {gpu_id_num}: {self.get_gpu_name(gpu_id_num)}")
        else:
            os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
            self.device = "cpu"
            logger.info("Using CPU")
    
    def get_gpu_name(self, gpu_id: int = 0) -> str:
        """‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á GPU ‡∏ï‡∏≤‡∏° ID"""
        if self.gpu_info and gpu_id < len(self.gpu_info):
            return self.gpu_info[gpu_id]["name"]
        return "Unknown"
    
    def _initialize_systems(self):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö TTS ‡πÅ‡∏•‡∏∞ RVC"""
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô TTS
        try:
            import edge_tts
            self.tts_available = True
            logger.info("‚úÖ Edge TTS system loaded")
        except ImportError:
            logger.warning("‚ö†Ô∏è Edge TTS not available")
        
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô RVC
        try:
            from rvc_api import RVCConverter
            self.rvc_instance = RVCConverter(
                device=self.device, 
                models_dir=str(self.models_dir),
                performance_config=self.performance_config
            )
            self.rvc_available = True
            logger.info(f"‚úÖ RVC system loaded on {self.device}")
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è RVC system not available: {e}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è RVC system initialization failed: {e}")
    
    def get_system_status(self) -> Dict[str, Any]:
        """‡∏î‡∏∂‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡∏∞‡∏ö‡∏ö"""
        return {
            "tts_available": self.tts_available,
            "rvc_available": self.rvc_available,
            "device": self.device,
            "gpu_name": self.get_gpu_name(int(self.device.split(':')[-1])) if "cuda" in self.device and self.gpu_available else "CPU",
            "rvc_models_count": len(self.get_available_rvc_models()) if self.rvc_available else 0
        }
    
    async def test_edge_tts_connection(self, voice: str = "th-TH-PremwadeeNeural") -> bool:
        """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Edge TTS"""
        try:
            import edge_tts
            
            # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡πÜ
            test_text = "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ"
            communicate = edge_tts.Communicate(text=test_text, voice=voice)
            
            audio_data = b""
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    audio_data += chunk["data"]
            
            if audio_data:
                logger.info(f"Edge TTS connection test successful with voice: {voice}")
                return True
            else:
                logger.error(f"Edge TTS connection test failed - no audio received for voice: {voice}")
                return False
                
        except Exception as e:
            logger.error(f"Edge TTS connection test failed: {e}")
            return False
    
    async def get_available_edge_voices(self) -> List[str]:
        """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ voice ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô Edge TTS"""
        try:
            import edge_tts
            voices = await edge_tts.list_voices()
            return [voice["ShortName"] for voice in voices]
        except Exception as e:
            logger.error(f"Error getting Edge TTS voices: {e}")
            return []
    
    def get_available_rvc_models(self) -> List[str]:
        """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏• RVC ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà"""
        if not self.rvc_available:
            return []
        
        try:
            return self.rvc_instance.get_available_models()
        except Exception as e:
            logger.error(f"Error getting RVC models: {e}")
            return []
    
    async def generate_tts(self, text: str, voice: str, speed: float = 1.0, 
                          pitch: str = "+0Hz", enable_multi_language: bool = False) -> bytes:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ Edge TTS
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á
            voice: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (‡πÄ‡∏ä‡πà‡∏ô th-TH-PremwadeeNeural)
            speed: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î (0.5-2.0)
            pitch: ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡πÄ‡∏ä‡πà‡∏ô +0Hz, +10Hz)
            enable_multi_language: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤
            
        Returns:
            bytes: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö bytes
        """
        if not self.tts_available:
            raise Exception("TTS system not available")
        
        try:
            import edge_tts
            
            # Log ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå
            logger.info(f"Generating TTS with text='{text[:30]}...', voice='{voice}', speed={speed}, pitch={pitch}, multi_lang={enable_multi_language}")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            if not text or not text.strip():
                raise Exception("Text is empty or contains only whitespace")
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° - ‡∏•‡∏ö‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            cleaned_text = text.strip()
            cleaned_text = ''.join(char for char in cleaned_text if ord(char) >= 32 or char in '\n\r\t')
            
            if not cleaned_text:
                raise Exception("Text is empty after cleaning")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö voice
            if not voice or not voice.strip():
                raise Exception("Voice is not specified")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ voice ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            try:
                available_voices = await self.get_available_edge_voices()
                if voice not in available_voices:
                    logger.warning(f"Voice '{voice}' not found in available voices. Available voices: {available_voices[:5]}...")
                    # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ voice ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
                    fallback_voice = "th-TH-PremwadeeNeural"
                    if fallback_voice in available_voices:
                        logger.info(f"Using fallback voice: {fallback_voice}")
                        voice = fallback_voice
                    else:
                        raise Exception(f"Voice '{voice}' not available and no fallback voice found")
            except Exception as voice_error:
                logger.warning(f"Could not verify voice availability: {voice_error}")
                # ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö voice
            
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ ‡πÉ‡∏´‡πâ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤
            if enable_multi_language:
                language_segments = self.detect_language_segments(cleaned_text)
                logger.info(f"Detected {len(language_segments)} language segments: {[(seg[:20] + '...' if len(seg) > 20 else seg, lang) for seg, lang in language_segments]}")
                
                if len(language_segments) > 1:
                    # ‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ ‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô
                    all_audio_data = []
                    
                    # ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
                    max_concurrent = self.performance_config.get("tts_max_concurrent", 1)
                    
                    # ‡∏Å‡∏£‡∏≠‡∏á segments ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
                    valid_segments = []
                    for segment_text, language in language_segments:
                        if not segment_text.strip():
                            continue
                        
                        # ‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏£‡∏£‡∏Ñ‡∏ï‡∏≠‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß‡πÜ
                        if language == 'punctuation' and len(segment_text.strip()) <= 2:
                            logger.debug(f"Skipping punctuation segment: '{segment_text}'")
                            continue
                        
                        valid_segments.append((segment_text, language))
                    
                    if max_concurrent > 1 and len(valid_segments) > 1:
                        # ‡πÉ‡∏ä‡πâ concurrent processing
                        logger.info(f"Processing {len(valid_segments)} segments with max_concurrent={max_concurrent}")
                        
                        semaphore = asyncio.Semaphore(max_concurrent)
                        
                        async def process_segment(segment_text, language):
                            async with semaphore:
                                segment_voice = self.get_voice_for_language(language, voice)
                                logger.info(f"Processing segment '{segment_text[:30]}...' with language '{language}' using voice '{segment_voice}'")
                                
                                try:
                                    segment_audio = await self._generate_single_tts(segment_text, segment_voice, speed, pitch)
                                    if segment_audio and len(segment_audio) > 0:
                                        return segment_audio
                                except Exception as e:
                                    logger.warning(f"Failed to generate audio for segment '{segment_text}': {e}")
                                    return None
                        
                        # ‡∏£‡∏±‡∏ô segments ‡πÅ‡∏ö‡∏ö concurrent
                        tasks = [process_segment(text, lang) for text, lang in valid_segments]
                        results = await asyncio.gather(*tasks, return_exceptions=True)
                        
                        # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                        for result in results:
                            if isinstance(result, bytes) and len(result) > 0:
                                all_audio_data.append(result)
                    else:
                        # ‡πÉ‡∏ä‡πâ sequential processing
                        for segment_text, language in valid_segments:
                            segment_voice = self.get_voice_for_language(language, voice)
                            logger.info(f"Processing segment '{segment_text[:30]}...' with language '{language}' using voice '{segment_voice}'")
                            
                            try:
                                segment_audio = await self._generate_single_tts(segment_text, segment_voice, speed, pitch)
                                if segment_audio and len(segment_audio) > 0:
                                    all_audio_data.append(segment_audio)
                            except Exception as e:
                                logger.warning(f"Failed to generate audio for segment '{segment_text}': {e}")
                                continue
                    
                    # ‡∏£‡∏ß‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                    if all_audio_data:
                        combined_audio = self._combine_audio_segments(all_audio_data)
                        logger.info(f"Multi-language TTS generated: {len(combined_audio)} bytes from {len(all_audio_data)} segments")
                        return combined_audio
                    else:
                        raise Exception("No audio was generated from any segments")
                else:
                    # ‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏¥‡∏°
                    logger.info("Single language detected, using standard TTS")
                    return await self._generate_single_tts(cleaned_text, voice, speed, pitch)
            else:
                # ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏¥‡∏°
                return await self._generate_single_tts(cleaned_text, voice, speed, pitch)
            
        except Exception as e:
            logger.error(f"TTS generation failed: {e}")
            raise Exception(f"TTS generation failed: {str(e)}")
    
    async def _generate_single_tts(self, text: str, voice: str, speed: float = 1.0, 
                                  pitch: str = "+0Hz") -> bytes:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á
            voice: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
            speed: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î
            pitch: ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            
        Returns:
            bytes: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö bytes
        """
        import edge_tts
        
        # ‡∏õ‡∏£‡∏±‡∏ö rate ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö speed
        if speed != 1.0:
            rate = f"{speed:+.0%}"
        else:
            rate = "+0%"
        
        logger.info(f"Generating single TTS: '{text[:50]}...' with voice '{voice}'")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Communicate object
        communicate = edge_tts.Communicate(
            text=text,
            voice=voice,
            rate=rate,
            pitch=pitch
        )
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        audio_data = b""
        chunk_count = 0
        
        try:
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    audio_data += chunk["data"]
                    chunk_count += 1
                elif chunk["type"] == "WordBoundary":
                    logger.debug(f"Word boundary: {chunk}")
                elif chunk["type"] == "SentenceBoundary":
                    logger.debug(f"Sentence boundary: {chunk}")
        except Exception as stream_error:
            logger.error(f"Error during streaming: {stream_error}")
            raise Exception(f"Streaming error: {str(stream_error)}")
        
        logger.info(f"Received {chunk_count} audio chunks")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if not audio_data:
            logger.error("No audio was received. Please verify that your parameters are correct.")
            raise Exception("No audio was received. Please verify that your parameters are correct.")
        
        logger.info(f"Single TTS generated: {len(audio_data)} bytes")
        return audio_data
    
    def _combine_audio_segments(self, audio_segments: List[bytes]) -> bytes:
        """
        ‡∏£‡∏ß‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
        
        Args:
            audio_segments: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            
        Returns:
            bytes: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡πÅ‡∏•‡πâ‡∏ß
        """
        try:
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤‡∏≠‡∏≠‡∏Å
            valid_segments = [seg for seg in audio_segments if seg and len(seg) > 0]
            
            if not valid_segments:
                raise Exception("No valid audio segments to combine")
            
            if len(valid_segments) == 1:
                # ‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏ß‡∏°
                return valid_segments[0]
            
            # Edge TTS ‡∏™‡πà‡∏á‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô MP3 ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏î‡πâ‡∏ß‡∏¢ pydub
            from pydub import AudioSegment
            import io
            
            combined_audio = None
            
            for i, segment_data in enumerate(valid_segments):
                try:
                    # ‡πÅ‡∏õ‡∏•‡∏á bytes ‡πÄ‡∏õ‡πá‡∏ô AudioSegment
                    audio_io = io.BytesIO(segment_data)
                    segment = AudioSegment.from_mp3(audio_io)
                    
                    if combined_audio is None:
                        combined_audio = segment
                    else:
                        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏á‡∏µ‡∏¢‡∏ö 100ms ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô
                        silence = AudioSegment.silent(duration=100)
                        combined_audio = combined_audio + silence + segment
                        
                except Exception as e:
                    logger.warning(f"Failed to process segment {i}: {e}")
                    # ‡∏ñ‡πâ‡∏≤‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≤‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏õ
                    continue
            
            if combined_audio is None:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏ß‡∏° bytes ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°
                logger.warning("Failed to combine with pydub, using byte concatenation")
                combined_bytes = b""
                for segment in valid_segments:
                    combined_bytes += segment
                return combined_bytes
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô MP3 bytes
            output_io = io.BytesIO()
            combined_audio.export(output_io, format="mp3")
            combined_bytes = output_io.getvalue()
            
            logger.info(f"Combined {len(valid_segments)} audio segments into {len(combined_bytes)} bytes")
            return combined_bytes
            
        except Exception as e:
            logger.error(f"Error combining audio segments: {e}")
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏ß‡∏°‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏£‡∏Å
            return audio_segments[0] if audio_segments else b""
    
    def convert_voice(self, audio_data: bytes, model_name: str, 
                     transpose: int = 0, index_ratio: float = 0.75,
                     f0_method: str = "rmvpe") -> bytes:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ RVC
        
        Args:
            audio_data: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á
            model_name: ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏• RVC
            transpose: ‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏±‡∏ö pitch (-12 ‡∏ñ‡∏∂‡∏á 12)
            index_ratio: ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô index (0.0-1.0)
            f0_method: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì f0
            
        Returns:
            bytes: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡πâ‡∏ß
        """
        if not self.rvc_available:
            raise Exception("RVC system not available")
        
        try:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô
            import time
            timestamp = int(time.time() * 1000)
            temp_input = self.temp_dir / f"rvc_input_{timestamp}.wav"
            temp_output = self.temp_dir / f"rvc_output_{timestamp}.wav"
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö WAV ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
            try:
                import io
                import soundfile as sf
                import numpy as np
                from pydub import AudioSegment
                
                # ‡∏•‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô MP3 ‡∏Å‡πà‡∏≠‡∏ô (Edge TTS ‡∏™‡πà‡∏á‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô MP3)
                try:
                    # ‡πÅ‡∏õ‡∏•‡∏á MP3 ‡πÄ‡∏õ‡πá‡∏ô WAV ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ pydub
                    audio_io = io.BytesIO(audio_data)
                    audio_segment = AudioSegment.from_mp3(audio_io)
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array
                    samples = np.array(audio_segment.get_array_of_samples())
                    
                    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô stereo ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô mono
                    if audio_segment.channels == 2:
                        samples = samples.reshape((-1, 2))
                        samples = np.mean(samples, axis=1)
                    
                    # Normalize audio
                    samples = samples.astype(np.float32) / 32768.0
                    
                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô WAV
                    sf.write(str(temp_input), samples, audio_segment.frame_rate, format='WAV', subtype='PCM_16')
                    
                    logger.info(f"Converted MP3 to WAV: {temp_input} (sample_rate={audio_segment.frame_rate})")
                    
                except Exception as mp3_error:
                    logger.debug(f"Not MP3 format or pydub conversion failed: {mp3_error}")
                    
                    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà MP3 ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô WAV ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
                    audio_io = io.BytesIO(audio_data)
                    audio_array, sample_rate = sf.read(audio_io)
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô mono ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô stereo
                    if len(audio_array.shape) > 1:
                        audio_array = np.mean(audio_array, axis=1)
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á
                    if np.isnan(audio_array).any():
                        audio_array = np.nan_to_num(audio_array, nan=0.0)
                    
                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå WAV ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
                    sf.write(str(temp_input), audio_array, sample_rate, format='WAV', subtype='PCM_16')
                    
                    logger.info(f"Saved audio as WAV: {temp_input} (sample_rate={sample_rate})")
                
            except Exception as conversion_error:
                logger.error(f"Failed to convert audio format: {conversion_error}")
                
                # ‡∏ñ‡πâ‡∏≤‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ ffmpeg
                temp_mp3 = self.temp_dir / f"temp_{timestamp}.mp3"
                with open(temp_mp3, "wb") as f:
                    f.write(audio_data)
                
                # ‡πÉ‡∏ä‡πâ ffmpeg ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô WAV
                import subprocess
                ffmpeg_cmd = [
                    "ffmpeg", "-y", "-i", str(temp_mp3),
                    "-acodec", "pcm_s16le", "-ar", "44100", "-ac", "1",
                    str(temp_input)
                ]
                
                result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)
                if result.returncode != 0:
                    logger.error(f"FFmpeg conversion failed: {result.stderr}")
                    raise Exception(f"Audio format conversion failed: {result.stderr}")
                
                # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå MP3 ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
                temp_mp3.unlink(missing_ok=True)
                logger.info(f"Converted audio using FFmpeg: {temp_input}")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if not temp_input.exists():
                raise Exception("Failed to create input audio file")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå
            file_size = temp_input.stat().st_size
            if file_size == 0:
                raise Exception("Input audio file is empty")
            
            logger.info(f"Created input file: {temp_input} ({file_size} bytes)")
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            result_path = self.rvc_instance.convert_voice(
                input_path=str(temp_input),
                output_path=str(temp_output),
                model_name=model_name,
                transpose=transpose,
                index_ratio=index_ratio,
                f0_method=f0_method
            )
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if result_path is None:
                raise Exception("RVC conversion failed - no output path returned")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if not Path(result_path).exists():
                raise Exception(f"RVC output file not found: {result_path}")
            
            # ‡∏≠‡πà‡∏≤‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            with open(result_path, "rb") as f:
                converted_audio = f.read()
            
            if len(converted_audio) == 0:
                raise Exception("RVC output file is empty")
            
            # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
            try:
                temp_input.unlink(missing_ok=True)
                if Path(result_path) != temp_output:
                    Path(result_path).unlink(missing_ok=True)
                temp_output.unlink(missing_ok=True)
            except Exception as cleanup_error:
                logger.warning(f"Failed to cleanup temp files: {cleanup_error}")
            
            logger.info(f"Voice conversion completed: {len(converted_audio)} bytes")
            return converted_audio
            
        except Exception as e:
            logger.error(f"Voice conversion failed: {e}")
            # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ error
            try:
                temp_input.unlink(missing_ok=True)
                temp_output.unlink(missing_ok=True)
            except:
                pass
            raise Exception(f"Voice conversion failed: {str(e)}")
    
    async def process_unified(self, text: str, tts_voice: str, 
                            enable_rvc: bool = False, rvc_model: str = None,
                            tts_speed: float = 1.0, tts_pitch: str = "+0Hz",
                            rvc_transpose: int = 0, rvc_index_ratio: float = 0.75,
                            rvc_f0_method: str = "rmvpe", enable_multi_language: bool = False) -> Dict[str, Any]:
        """
        ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏ß‡∏° TTS + RVC ‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á
            tts_voice: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á TTS
            enable_rvc: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ RVC ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            rvc_model: ‡πÇ‡∏°‡πÄ‡∏î‡∏• RVC (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ)
            tts_speed: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß TTS
            tts_pitch: ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á TTS
            rvc_transpose: ‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏±‡∏ö pitch RVC
            rvc_index_ratio: ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô index RVC
            rvc_f0_method: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ f0 RVC
            enable_multi_language: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤
            
        Returns:
            Dict: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
        """
        result = {
            "success": False,
            "tts_audio_data": None,
            "rvc_audio_data": None,
            "final_audio_data": None,
            "processing_steps": [],
            "error": None,
            "stats": {}
        }
        
        try:
            # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á TTS
            logger.info("Step 1: Generating TTS...")
            tts_audio = await self.generate_tts(text, tts_voice, tts_speed, tts_pitch, enable_multi_language)
            result["processing_steps"].append("tts_generation")
            result["stats"]["tts_audio_size"] = len(tts_audio)
            result["tts_audio_data"] = tts_audio
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤
            if enable_multi_language:
                language_segments = self.detect_language_segments(text)
                result["stats"]["language_segments"] = len(language_segments)
                result["stats"]["detected_languages"] = list(set(lang for _, lang in language_segments))
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤
                language_segments_detail = []
                for segment_text, language in language_segments:
                    voice = self.get_voice_for_language(language, tts_voice)
                    language_segments_detail.append({
                        "text": segment_text,
                        "language": language,
                        "voice": voice
                    })
                result["stats"]["language_segments_detail"] = language_segments_detail
                
                logger.info(f"Detected languages: {result['stats']['detected_languages']}")
                logger.info(f"Language segments: {len(language_segments)} segments")
            
            final_audio = tts_audio
            rvc_audio = None
            
            # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ RVC (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ)
            if enable_rvc and rvc_model:
                logger.info(f"Step 2: Checking RVC model '{rvc_model}'...")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ RVC system ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                if not self.rvc_available:
                    logger.warning("RVC system not available")
                    result["processing_steps"].append("rvc_unavailable")
                    result["error"] = "RVC system not available"
                else:
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    available_models = self.get_available_rvc_models()
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á rvc_model ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô string ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç unhashable error)
                    rvc_model, model_error = safe_model_processing(
                        rvc_model, 
                        available_models,
                        available_models[0] if available_models else None
                    )
                    
                    if model_error:
                        logger.warning(f"Model processing warning: {model_error}")
                    
                    if rvc_model and rvc_model not in available_models:
                        logger.warning(f"RVC model '{rvc_model}' not found. Available models: {available_models}")
                        result["processing_steps"].append("rvc_model_not_found")
                        result["error"] = f"RVC model '{rvc_model}' not found"
                    else:
                        logger.info(f"Step 2: Applying voice conversion with model '{rvc_model}'...")
                        try:
                            converted_audio = self.convert_voice(
                                tts_audio, rvc_model, rvc_transpose, 
                                rvc_index_ratio, rvc_f0_method
                            )
                            rvc_audio = converted_audio
                            final_audio = converted_audio
                            result["processing_steps"].append("voice_conversion")
                            result["stats"]["rvc_audio_size"] = len(converted_audio)
                            result["rvc_audio_data"] = converted_audio
                            logger.info(f"Voice conversion successful: {len(converted_audio)} bytes")
                        except Exception as rvc_error:
                            logger.error(f"Voice conversion failed: {rvc_error}")
                            result["processing_steps"].append("rvc_failed")
                            result["error"] = f"Voice conversion failed: {str(rvc_error)}"
                            # ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á TTS ‡πÄ‡∏î‡∏¥‡∏°
            elif enable_rvc and not rvc_model:
                logger.warning("RVC enabled but no model specified")
                result["processing_steps"].append("rvc_no_model")
                result["error"] = "RVC enabled but no model specified"
            
            # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            result.update({
                "success": True,
                "final_audio_data": final_audio,
                "stats": {
                    **result["stats"],
                    "text_length": len(text),
                    "final_audio_size": len(final_audio),
                    "voice_conversion_applied": "voice_conversion" in result["processing_steps"],
                    "multi_language_enabled": enable_multi_language,
                    "device": self.device
                }
            })
            
            logger.info(f"Unified processing completed: {result['processing_steps']}")
            return result
            
        except Exception as e:
            logger.error(f"Unified processing failed: {e}")
            result.update({
                "success": False,
                "error": str(e)
            })
            return result
    
    def smart_chunk_text(self, text: str, max_chunk_size: int = 8000) -> List[str]:
        """
        ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ç‡∏â‡∏•‡∏≤‡∏î ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á TTS
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á
            max_chunk_size: ‡∏Ç‡∏ô‡∏≤‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
            
        Returns:
            List[str]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß
        """
        if len(text) <= max_chunk_size:
            return [text]
        
        chunks = []
        current_chunk = ""
        
        # ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
        sentences = text.replace(".", ".\\n").replace("!", "!\\n").replace("?", "?\\n").split("\\n")
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡πâ‡∏ß‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î
            if len(current_chunk) + len(sentence) + 1 <= max_chunk_size:
                if current_chunk:
                    current_chunk += " " + sentence
                else:
                    current_chunk = sentence
            else:
                # ‡πÄ‡∏Å‡πá‡∏ö chunk ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                if current_chunk:
                    chunks.append(current_chunk)
                
                # ‡πÄ‡∏£‡∏¥‡πà‡∏° chunk ‡πÉ‡∏´‡∏°‡πà
                if len(sentence) <= max_chunk_size:
                    current_chunk = sentence
                else:
                    # ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥
                    words = sentence.split()
                    temp_chunk = ""
                    for word in words:
                        if len(temp_chunk) + len(word) + 1 <= max_chunk_size:
                            if temp_chunk:
                                temp_chunk += " " + word
                            else:
                                temp_chunk = word
                        else:
                            if temp_chunk:
                                chunks.append(temp_chunk)
                            temp_chunk = word
                    current_chunk = temp_chunk
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° chunk ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        if current_chunk:
            chunks.append(current_chunk)
        
        logger.info(f"Text chunked into {len(chunks)} parts")
        return chunks
    
    async def process_long_text(self, text: str, tts_voice: str,
                               max_chunk_size: int = 8000, **kwargs) -> Dict[str, Any]:
        """
        ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á chunk
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß
            tts_voice: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á TTS
            max_chunk_size: ‡∏Ç‡∏ô‡∏≤‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ chunk
            **kwargs: ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö process_unified
            
        Returns:
            Dict: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏£‡∏ß‡∏°‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å chunk
        """
        # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        chunks = self.smart_chunk_text(text, max_chunk_size)
        
        if len(chunks) == 1:
            # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô ‡πÉ‡∏ä‡πâ process_unified ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
            return await self.process_unified(text, tts_voice, **kwargs)
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• chunk ‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß
        all_audio_data = []
        all_processing_steps = []
        total_stats = {
            "chunks_count": len(chunks),
            "total_text_length": len(text),
            "chunk_sizes": [len(chunk) for chunk in chunks]
        }
        
        for i, chunk in enumerate(chunks):
            logger.info(f"Processing chunk {i+1}/{len(chunks)}: {len(chunk)} chars")
            
            chunk_result = await self.process_unified(chunk, tts_voice, **kwargs)
            
            if chunk_result["success"]:
                all_audio_data.append(chunk_result["audio_data"])
                all_processing_steps.extend([f"chunk_{i+1}_{step}" for step in chunk_result["processing_steps"]])
            else:
                logger.error(f"Chunk {i+1} failed: {chunk_result.get('error')}")
                return {
                    "success": False,
                    "error": f"Chunk {i+1} processing failed: {chunk_result.get('error')}",
                    "chunks_processed": i
                }
            
            # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á chunk
            await asyncio.sleep(0.1)
        
        # ‡∏£‡∏ß‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        try:
            combined_audio = b"".join(all_audio_data)
            
            return {
                "success": True,
                "audio_data": combined_audio,
                "processing_steps": all_processing_steps,
                "stats": {
                    **total_stats,
                    "final_audio_size": len(combined_audio),
                    "chunks_processed": len(chunks),
                    "processing_method": "multi_chunk",
                    "device": self.device
                }
            }
        except Exception as e:
            logger.error(f"Audio combination failed: {e}")
            return {
                "success": False,
                "error": f"Audio combination failed: {str(e)}",
                "chunks_processed": len(chunks)
            }
    
    def cleanup_temp_files(self):
        """‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤"""
        try:
            import time
            current_time = time.time()
            cutoff_time = current_time - 3600  # 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
            
            for file_path in self.temp_dir.glob("*"):
                if file_path.is_file() and file_path.stat().st_mtime < cutoff_time:
                    file_path.unlink(missing_ok=True)
            
            logger.info("Temp files cleaned")
        except Exception as e:
            logger.error(f"Cleanup error: {e}")
            
    def change_device(self, new_device: str = None, use_gpu: bool = None, gpu_id: int = None):
        """
        ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        
        Args:
            new_device: ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÉ‡∏´‡∏°‡πà (cpu, cuda:0, cuda:1, ...)
            use_gpu: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô GPU ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            gpu_id: ID ‡∏Ç‡∏≠‡∏á GPU ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (0, 1, 2, ...)
        
        Returns:
            bool: True ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à, False ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
        """
        try:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡∏°‡πà ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°
            if use_gpu is None:
                use_gpu = "cuda" in self.device
            if gpu_id is None and "cuda:" in self.device:
                gpu_id = int(self.device.split(":")[-1])
            elif gpu_id is None:
                gpu_id = 0
                
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å device ‡πÄ‡∏î‡∏¥‡∏°
            old_device = self.device
            
            # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ device ‡πÉ‡∏´‡∏°‡πà
            self.setup_device(new_device, use_gpu, gpu_id)
            
            # ‡∏ñ‡πâ‡∏≤ device ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà
            if old_device != self.device:
                logger.info(f"Device changed from {old_device} to {self.device}, reinitializing systems")
                self._initialize_systems()
                return True
            
            return False
        except Exception as e:
            logger.error(f"Error changing device: {e}")
            return False
    
    def get_device_info(self) -> Dict[str, Any]:
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ"""
        return {
            "current_device": self.device,
            "gpu_available": self.gpu_available,
            "gpu_count": len(self.gpu_info) if self.gpu_info else 0,
            "gpu_info": self.gpu_info or [],
            "device_options": self._get_device_options()
        }
    
    def _get_device_options(self) -> List[Dict[str, Any]]:
        """‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ"""
        options = [
            {
                "value": "cpu",
                "label": "CPU Only",
                "description": "‡πÉ‡∏ä‡πâ CPU ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)",
                "icon": "üñ•Ô∏è"
            }
        ]
        
        if self.gpu_available and self.gpu_info:
            for gpu in self.gpu_info:
                options.append({
                    "value": f"cuda:{gpu['id']}",
                    "label": f"GPU {gpu['id']}: {gpu['name']}",
                    "description": f"‡πÉ‡∏ä‡πâ GPU {gpu['id']} ({gpu['memory']:.1f}GB)",
                    "icon": "üöÄ"
                })
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å AUTO
            if len(self.gpu_info) > 0:
                options.append({
                    "value": "auto",
                    "label": "AUTO (Best GPU)",
                    "description": "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å GPU ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥",
                    "icon": "‚ö°"
                })
        
        return options
    
    def change_device_auto(self, device_choice: str) -> Dict[str, Any]:
        """
        ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
        
        Args:
            device_choice: ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (cpu, cuda:0, cuda:1, auto)
        """
        try:
            if device_choice == "auto":
                # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å GPU ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (memory ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
                if self.gpu_available and self.gpu_info:
                    best_gpu = max(self.gpu_info, key=lambda x: x['memory'])
                    device_choice = f"cuda:{best_gpu['id']}"
                    logger.info(f"Auto-selected GPU {best_gpu['id']}: {best_gpu['name']} ({best_gpu['memory']:.1f}GB)")
                else:
                    device_choice = "cpu"
                    logger.info("No GPU available, using CPU")
            
            # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå
            success = self.change_device(device_choice)
            
            return {
                "success": success,
                "device": self.device,
                "device_info": self.get_device_info(),
                "message": f"Changed to {self.device}"
            }
            
        except Exception as e:
            logger.error(f"Error in change_device_auto: {e}")
            return {
                "success": False,
                "error": str(e),
                "device": self.device
            }

    def detect_language_segments(self, text: str) -> List[Tuple[str, str]]:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å
            
        Returns:
            List[Tuple[str, str]]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°, ‡∏†‡∏≤‡∏©‡∏≤)
        """
        if not text.strip():
            return []
        
        segments = []
        
        # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
        patterns = {
            'english': r'[a-zA-Z]+(?:\\s+[a-zA-Z]+)*',
            'lao': r'[\u0E80-\u0EFF]+(?:\\s+[\u0E80-\u0EFF]+)*',
            'thai': r'[\u0E00-\u0E7F]+(?:\\s+[\u0E00-\u0E7F]+)*',
            'chinese': r'[\u4E00-\u9FFF]+(?:\\s+[\u4E00-\u9FFF]+)*',
            'japanese': r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]+(?:\\s+[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]+)*',
            'numbers': r'\\d+(?:\\.\\d+)?',
            'punctuation': r'[^\\w\\s\u0E00-\u0E7F\u0E80-\u0EFF\u4E00-\u9FFF\u3040-\u309F\u30A0-\u30FF]'
        }
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏•‡∏≤‡∏ß‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        has_lao = bool(re.search(r'[\u0E80-\u0EFF]', text))
        has_english = bool(re.search(r'[a-zA-Z]', text))
        
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏•‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ multi-language detection
        if has_lao and has_english:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á regex pattern ‡∏£‡∏ß‡∏°‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
            all_patterns = []
            for lang_code, pattern in patterns.items():
                all_patterns.append(f'(?P<{lang_code}>{pattern})')
            
            combined_pattern = '|'.join(all_patterns)
            
            # ‡∏´‡∏≤ matches ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            matches = list(re.finditer(combined_pattern, text, re.UNICODE))
            
            if not matches:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÜ ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏•‡∏≤‡∏ß
                return [(text, 'lao')]
            
            # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
            matches.sort(key=lambda x: x.start())
            
            # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ
            current_pos = 0
            
            for match in matches:
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÜ (‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á, ‡∏Ø‡∏•‡∏Ø)
                if match.start() > current_pos:
                    gap_text = text[current_pos:match.start()]
                    if gap_text.strip():
                        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á
                        surrounding_lang = self._determine_surrounding_language(matches, current_pos)
                        segments.append((gap_text, surrounding_lang))
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
                for lang_code in patterns.keys():
                    if match.group(lang_code):
                        segments.append((match.group(lang_code), lang_code))
                        break
                
                current_pos = match.end()
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
            if current_pos < len(text):
                remaining_text = text[current_pos:]
                if remaining_text.strip():
                    surrounding_lang = self._determine_surrounding_language(matches, current_pos)
                    segments.append((remaining_text, surrounding_lang))
            
            # ‡∏£‡∏ß‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
            merged_segments = self._merge_adjacent_segments(segments)
            
            return merged_segments
        else:
            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
            if has_lao:
                return [(text, 'lao')]
            elif has_english:
                return [(text, 'english')]
            else:
                return [(text, 'unknown')]
        

    
    def _determine_surrounding_language(self, matches: List, position: int) -> str:
        """‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á"""
        # ‡∏´‡∏≤ match ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        closest_match = None
        min_distance = float('inf')
        
        for match in matches:
            distance = min(abs(match.start() - position), abs(match.end() - position))
            if distance < min_distance:
                min_distance = distance
                closest_match = match
        
        if closest_match:
            # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≤‡∏° match ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
            for lang_code in ['lao', 'thai', 'english', 'chinese', 'japanese', 'numbers', 'punctuation']:
                if closest_match.group(lang_code):
                    return lang_code
        
        return 'lao'  # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    
    def _merge_adjacent_segments(self, segments: List[Tuple[str, str]]) -> List[Tuple[str, str]]:
        """‡∏£‡∏ß‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô"""
        if not segments:
            return []
        
        merged = []
        current_text = segments[0][0]
        current_lang = segments[0][1]
        
        for text, lang in segments[1:]:
            # ‡∏£‡∏ß‡∏°‡∏ñ‡πâ‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
            if lang == current_lang:
                current_text += text
            else:
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                merged.append((current_text, current_lang))
                # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏°‡πà
                current_text = text
                current_lang = lang
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        merged.append((current_text, current_lang))
        
        return merged
    
    def get_voice_for_language(self, language: str, base_voice: str) -> str:
        """
        ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤
        
        Args:
            language: ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            base_voice: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            
        Returns:
            str: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
        """
        # ‡πÅ‡∏°‡∏õ‡∏õ‡∏¥‡πâ‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        language_voice_mapping = {
            'english': 'en-US-AriaNeural',
            'lao': 'lo-LA-KeomanyNeural',
            'thai': 'th-TH-PremwadeeNeural',
            'chinese': 'zh-CN-XiaoxiaoNeural',
            'japanese': 'ja-JP-NanamiNeural'
        }
        
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏£‡∏£‡∏Ñ‡∏ï‡∏≠‡∏ô ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á
        if language in ['numbers', 'punctuation']:
            return base_voice
        
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô unknown ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        if language == 'unknown':
            return 'lo-LA-KeomanyNeural'
        
        return language_voice_mapping.get(language, base_voice)

    def apply_audio_effects(self, audio_data: bytes, effects: Dict[str, Any]) -> bytes:
        """
        ‡πÉ‡∏ä‡πâ‡πÄ‡∏≠‡∏ü‡πÄ‡∏ü‡∏Å‡∏ï‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏Å‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        
        Args:
            audio_data: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏™‡πà‡πÄ‡∏≠‡∏ü‡πÄ‡∏ü‡∏Å‡∏ï‡πå
            effects: dictionary ‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏ü‡πÄ‡∏ü‡∏Å‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            
        Returns:
            bytes: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏™‡πà‡πÄ‡∏≠‡∏ü‡πÄ‡∏ü‡∏Å‡∏ï‡πå‡πÅ‡∏•‡πâ‡∏ß
        """
        try:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏≠‡∏ü‡πÄ‡∏ü‡∏Å‡∏ï‡πå‡πÉ‡∏î‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà ‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏î‡∏¥‡∏°
            if not any(effects.get(key, False) for key in ['demon_mode', 'robot_mode', 'echo_mode', 'reverb_mode']):
                return audio_data
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å bytes ‡πÄ‡∏õ‡πá‡∏ô numpy array
            import io
            import soundfile as sf
            from pedalboard import (
                Pedalboard, Chorus, Distortion, Reverb, PitchShift, 
                Limiter, Gain, Bitcrush, Clipping, Compressor, Delay
            )
            
            # ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å bytes
            audio_io = io.BytesIO(audio_data)
            audio_array, sample_rate = sf.read(audio_io)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á pedalboard
            board = Pedalboard()
            
            # Demon Mode: Pitch down + Distortion + Dark reverb
            if effects.get('demon_mode', False):
                logger.info("Applying demon mode effect")
                # ‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡∏á 8 semitones
                pitch_shift = PitchShift(semitones=-8)
                board.append(pitch_shift)
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏° distortion
                distortion = Distortion(drive_db=35)
                board.append(distortion)
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏° dark reverb
                reverb = Reverb(
                    room_size=0.9,
                    damping=0.8,
                    wet_level=0.4,
                    dry_level=0.7,
                    width=0.5
                )
                board.append(reverb)
            
            # Robot Mode: Bitcrush + Chorus + High pitch
            if effects.get('robot_mode', False):
                logger.info("Applying robot mode effect")
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏∂‡πâ‡∏ô 2 semitones
                pitch_shift = PitchShift(semitones=2)
                board.append(pitch_shift)
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏° bitcrush ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡∏¥‡∏à‡∏¥‡∏ï‡∏≠‡∏•
                bitcrush = Bitcrush(bit_depth=6)
                board.append(bitcrush)
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏° chorus ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏õ‡∏•‡∏Å‡πÜ
                chorus = Chorus(
                    rate_hz=2.0,
                    depth=0.5,
                    centre_delay_ms=10,
                    feedback=0.3,
                    mix=0.6
                )
                board.append(chorus)
            
            # Echo Mode: Delay effect
            if effects.get('echo_mode', False):
                logger.info("Applying echo mode effect")
                delay = Delay(
                    delay_seconds=0.3,
                    feedback=0.5,
                    mix=0.4
                )
                board.append(delay)
            
            # Reverb Mode: Natural reverb
            if effects.get('reverb_mode', False):
                logger.info("Applying reverb mode effect")
                reverb = Reverb(
                    room_size=0.7,
                    damping=0.3,
                    wet_level=0.5,
                    dry_level=0.8,
                    width=1.0
                )
                board.append(reverb)
            
            # ‡πÉ‡∏ä‡πâ‡πÄ‡∏≠‡∏ü‡πÄ‡∏ü‡∏Å‡∏ï‡πå‡∏Å‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            if len(board) > 0:
                processed_audio = board(audio_array, sample_rate)
                
                # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô bytes
                output_io = io.BytesIO()
                sf.write(output_io, processed_audio, sample_rate, format='WAV')
                processed_data = output_io.getvalue()
                
                logger.info(f"Applied {len(board)} audio effects, size: {len(audio_data)} -> {len(processed_data)} bytes")
                return processed_data
            else:
                return audio_data
                
        except Exception as e:
            logger.error(f"Error applying audio effects: {e}")
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏î‡∏¥‡∏°
            return audio_data

# ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
SUPPORTED_VOICES = {
    "th-TH-PremwadeeNeural": {"name": "Premwadee (Thai Female)", "gender": "Female", "language": "Thai"},
    "th-TH-NiranNeural": {"name": "Niran (Thai Male)", "gender": "Male", "language": "Thai"},
    "th-TH-NiwatNeural": {"name": "Niwat (Thai Male)", "gender": "Male", "language": "Thai"},
    "lo-LA-ChanthavongNeural": {"name": "Chanthavong (Lao Male)", "gender": "Male", "language": "Lao"},
    "lo-LA-KeomanyNeural": {"name": "Keomany (Lao Female)", "gender": "Female", "language": "Lao"},
    "en-US-AriaNeural": {"name": "Aria (US Female)", "gender": "Female", "language": "English"},
    "en-US-GuyNeural": {"name": "Guy (US Male)", "gender": "Male", "language": "English"},
    "en-US-JennyNeural": {"name": "Jenny (US Female)", "gender": "Female", "language": "English"},
    "ja-JP-NanamiNeural": {"name": "Nanami (Japanese Female)", "gender": "Female", "language": "Japanese"},
    "zh-CN-XiaoxiaoNeural": {"name": "Xiaoxiao (Chinese Female)", "gender": "Female", "language": "Chinese"}
}

# Helper functions
def create_core_instance(**kwargs) -> TTSRVCCore:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á instance ‡∏Ç‡∏≠‡∏á TTS-RVC Core"""
    return TTSRVCCore(**kwargs)

def get_supported_voices() -> Dict[str, Dict[str, str]]:
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö"""
    return SUPPORTED_VOICES

# Test function
async def test_core_system():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö Core"""
    print("üîß Testing TTS-RVC Core System...")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU
    try:
        import torch
        if torch.cuda.is_available():
            device = f"cuda:{torch.cuda.current_device()}"
            print(f"Found GPU: {torch.cuda.get_device_name(0)}")
        else:
            device = "cpu"
            print("No GPU available, using CPU")
    except ImportError:
        device = "cpu"
        print("PyTorch not available, using CPU")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á instance
    core = create_core_instance(device=device)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
    status = core.get_system_status()
    print(f"‚úÖ System Status: {status}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö TTS
    if status["tts_available"]:
        print("üéµ Testing TTS...")
        try:
            test_text = "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö TTS"
            audio_data = await core.generate_tts(test_text, "th-TH-PremwadeeNeural")
            print(f"‚úÖ TTS Test: {len(audio_data)} bytes generated")
        except Exception as e:
            print(f"‚ùå TTS Test failed: {e}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö RVC (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•)
    if status["rvc_available"] and status["rvc_models_count"] > 0:
        print("üé≠ Testing RVC...")
        try:
            # ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å TTS ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
            if 'audio_data' in locals():
                model_name = core.get_available_rvc_models()[0]
                converted = core.convert_voice(audio_data, model_name)
                print(f"‚úÖ RVC Test: {len(converted)} bytes converted using {model_name}")
        except Exception as e:
            print(f"‚ùå RVC Test failed: {e}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏ß‡∏°
    print("üöÄ Testing Unified Processing...")
    try:
        result = await core.process_unified(
            text="‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏ß‡∏° TTS ‡πÅ‡∏•‡∏∞ RVC",
            tts_voice="th-TH-PremwadeeNeural",
            enable_rvc=status["rvc_available"] and status["rvc_models_count"] > 0,
            rvc_model=core.get_available_rvc_models()[0] if status["rvc_models_count"] > 0 else None
        )
        print(f"‚úÖ Unified Test: {result['success']}, Steps: {result['processing_steps']}")
    except Exception as e:
        print(f"‚ùå Unified Test failed: {e}")
    
    print("üéâ Core system testing completed!")

if __name__ == "__main__":
    # ‡∏£‡∏±‡∏ô test
    asyncio.run(test_core_system())

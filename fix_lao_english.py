#!/usr/bin/env python3
"""
Fix Multi-Language Detection for Lao + English
‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏£‡∏∞‡∏ö‡∏ö multi-language detection ‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡∏•‡∏≤‡∏ß‡πÑ‡∏î‡πâ
"""

import re
import logging
from pathlib import Path

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def fix_tts_rvc_core():
    """‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå tts_rvc_core.py ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á multi-language detection"""
    
    core_file = Path("tts_rvc_core.py")
    if not core_file.exists():
        logger.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå tts_rvc_core.py")
        return False
    
    # ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
    with open(core_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô detect_language_segments
    old_function = '''    def detect_language_segments(self, text: str) -> List[Tuple[str, str]]:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å
            
        Returns:
            List[Tuple[str, str]]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°, ‡∏†‡∏≤‡∏©‡∏≤)
        """
        segments = []
        
        # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤
        patterns = {
            'english': r'[a-zA-Z]+(?:\s+[a-zA-Z]+)*',
            'lao': r'[\u0E80-\u0EFF]+(?:\s+[\u0E80-\u0EFF]+)*',
            'thai': r'[\u0E00-\u0E7F]+(?:\s+[\u0E00-\u0E7F]+)*',
            'chinese': r'[\u4E00-\u9FFF]+(?:\s+[\u4E00-\u9FFF]+)*',
            'japanese': r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]+(?:\s+[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]+)*',
            'numbers': r'\d+(?:\.\d+)?',
            'punctuation': r'[^\w\s\u0E00-\u0E7F\u0E80-\u0EFF\u4E00-\u9FFF\u3040-\u309F\u30A0-\u30FF]'
        }
        
        # ‡∏£‡∏ß‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        all_patterns = '|'.join(f'({pattern})' for pattern in patterns.values())
        
        # ‡∏´‡∏≤ matches ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        matches = list(re.finditer(all_patterns, text, re.UNICODE))
        
        if not matches:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÜ ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            return [(text, 'unknown')]
        
        # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
        matches.sort(key=lambda x: x.start())
        
        current_pos = 0
        for match in matches:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÜ
            if match.start() > current_pos:
                unknown_text = text[current_pos:match.start()].strip()
                if unknown_text:
                    segments.append((unknown_text, 'unknown'))
            
            # ‡∏£‡∏∞‡∏ö‡∏∏‡∏†‡∏≤‡∏©‡∏≤
            matched_text = match.group()
            language = 'unknown'
            
            for i, (lang, pattern) in enumerate(patterns.items()):
                if re.match(pattern, matched_text, re.UNICODE):
                    language = lang
                    break
            
            segments.append((matched_text, language))
            current_pos = match.end()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
        if current_pos < len(text):
            remaining_text = text[current_pos:].strip()
            if remaining_text:
                segments.append((remaining_text, 'unknown'))
        
        # ‡∏£‡∏ß‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
        merged_segments = []
        current_text = ""
        current_lang = None
        
        for text_segment, lang in segments:
            if current_lang is None:
                current_lang = lang
                current_text = text_segment
            elif lang == current_lang:
                current_text += " " + text_segment
            else:
                if current_text:
                    merged_segments.append((current_text.strip(), current_lang))
                current_text = text_segment
                current_lang = lang
        
        if current_text:
            merged_segments.append((current_text.strip(), current_lang))
        
        return merged_segments'''
    
    new_function = '''    def detect_language_segments(self, text: str) -> List[Tuple[str, str]]:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å
            
        Returns:
            List[Tuple[str, str]]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°, ‡∏†‡∏≤‡∏©‡∏≤)
        """
        if not text.strip():
            return []
        
        segments = []
        
        # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
        patterns = {
            'english': r'[a-zA-Z]+(?:\\s+[a-zA-Z]+)*',
            'lao': r'[\\u0E80-\\u0EFF]+(?:\\s+[\\u0E80-\\u0EFF]+)*',
            'thai': r'[\\u0E00-\\u0E7F]+(?:\\s+[\\u0E00-\\u0E7F]+)*',
            'chinese': r'[\\u4E00-\\u9FFF]+(?:\\s+[\\u4E00-\\u9FFF]+)*',
            'japanese': r'[\\u3040-\\u309F\\u30A0-\\u30FF\\u4E00-\\u9FFF]+(?:\\s+[\\u3040-\\u309F\\u30A0-\\u30FF\\u4E00-\\u9FFF]+)*',
            'numbers': r'\\d+(?:\\.\\d+)?',
            'punctuation': r'[^\\w\\s\\u0E00-\\u0E7F\\u0E80-\\u0EFF\\u4E00-\\u9FFF\\u3040-\\u309F\\u30A0-\\u30FF]'
        }
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á regex pattern ‡∏£‡∏ß‡∏°‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
        all_patterns = []
        for lang_code, pattern in patterns.items():
            all_patterns.append(f'(?P<{lang_code}>{pattern})')
        
        combined_pattern = '|'.join(all_patterns)
        
        # ‡∏´‡∏≤ matches ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        matches = list(re.finditer(combined_pattern, text, re.UNICODE))
        
        if not matches:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÜ ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏•‡∏≤‡∏ß
            return [(text, 'lao')]
        
        # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
        matches.sort(key=lambda x: x.start())
        
        # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ
        current_pos = 0
        
        for match in matches:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÜ (‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á, ‡∏Ø‡∏•‡∏Ø)
            if match.start() > current_pos:
                gap_text = text[current_pos:match.start()]
                if gap_text.strip():
                    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á
                    surrounding_lang = self._determine_surrounding_language(matches, current_pos)
                    segments.append((gap_text, surrounding_lang))
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
            for lang_code in patterns.keys():
                if match.group(lang_code):
                    segments.append((match.group(lang_code), lang_code))
                    break
            
            current_pos = match.end()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
        if current_pos < len(text):
            remaining_text = text[current_pos:]
            if remaining_text.strip():
                surrounding_lang = self._determine_surrounding_language(matches, current_pos)
                segments.append((remaining_text, surrounding_lang))
        
        # ‡∏£‡∏ß‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
        merged_segments = self._merge_adjacent_segments(segments)
        
        return merged_segments
    
    def _determine_surrounding_language(self, matches: List, position: int) -> str:
        """‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á"""
        # ‡∏´‡∏≤ match ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        closest_match = None
        min_distance = float('inf')
        
        for match in matches:
            distance = min(abs(match.start() - position), abs(match.end() - position))
            if distance < min_distance:
                min_distance = distance
                closest_match = match
        
        if closest_match:
            # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≤‡∏° match ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
            for lang_code in ['lao', 'thai', 'english', 'chinese', 'japanese', 'numbers', 'punctuation']:
                if closest_match.group(lang_code):
                    return lang_code
        
        return 'lao'  # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    
    def _merge_adjacent_segments(self, segments: List[Tuple[str, str]]) -> List[Tuple[str, str]]:
        """‡∏£‡∏ß‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô"""
        if not segments:
            return []
        
        merged = []
        current_text = segments[0][0]
        current_lang = segments[0][1]
        
        for text, lang in segments[1:]:
            # ‡∏£‡∏ß‡∏°‡∏ñ‡πâ‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
            if lang == current_lang:
                current_text += text
            else:
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                merged.append((current_text, current_lang))
                # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏°‡πà
                current_text = text
                current_lang = lang
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        merged.append((current_text, current_lang))
        
        return merged'''
    
    # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô
    if old_function in content:
        content = content.replace(old_function, new_function)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà
        with open(core_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info("‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô detect_language_segments ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        return True
    else:
        logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô detect_language_segments ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå")
        return False

def update_get_voice_for_language():
    """‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô get_voice_for_language"""
    
    core_file = Path("tts_rvc_core.py")
    if not core_file.exists():
        logger.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå tts_rvc_core.py")
        return False
    
    with open(core_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô get_voice_for_language
    old_voice_function = '''    def get_voice_for_language(self, language: str, base_voice: str) -> str:
        """
        ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤
        
        Args:
            language: ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            base_voice: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            
        Returns:
            str: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
        """
        # ‡πÅ‡∏°‡∏õ‡∏õ‡∏¥‡πâ‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        language_voice_mapping = {
            'english': 'en-US-AriaNeural',
            'lao': 'lo-LA-KeomanyNeural',
            'thai': 'th-TH-PremwadeeNeural',
            'chinese': 'zh-CN-XiaoxiaoNeural',
            'japanese': 'ja-JP-NanamiNeural'
        }
        
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏£‡∏£‡∏Ñ‡∏ï‡∏≠‡∏ô ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        if language in ['numbers', 'punctuation', 'unknown']:
            return base_voice
        
        return language_voice_mapping.get(language, base_voice)'''
    
    new_voice_function = '''    def get_voice_for_language(self, language: str, base_voice: str) -> str:
        """
        ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤
        
        Args:
            language: ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            base_voice: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            
        Returns:
            str: ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
        """
        # ‡πÅ‡∏°‡∏õ‡∏õ‡∏¥‡πâ‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        language_voice_mapping = {
            'english': 'en-US-AriaNeural',
            'lao': 'lo-LA-KeomanyNeural',
            'thai': 'th-TH-PremwadeeNeural',
            'chinese': 'zh-CN-XiaoxiaoNeural',
            'japanese': 'ja-JP-NanamiNeural'
        }
        
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏£‡∏£‡∏Ñ‡∏ï‡∏≠‡∏ô ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≤‡∏á
        if language in ['numbers', 'punctuation']:
            return base_voice
        
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô unknown ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        if language == 'unknown':
            return 'lo-LA-KeomanyNeural'
        
        return language_voice_mapping.get(language, base_voice)'''
    
    # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô
    if old_voice_function in content:
        content = content.replace(old_voice_function, new_voice_function)
        
        with open(core_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info("‚úÖ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô get_voice_for_language ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        return True
    else:
        logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô get_voice_for_language ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå")
        return False

def create_test_script():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ó‡∏î‡∏™‡∏≠‡∏ö multi-language"""
    
    test_script = '''#!/usr/bin/env python3
"""
Test Multi-Language TTS for Lao + English
‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö multi-language TTS ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏•‡∏≤‡∏ß + ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
"""

import asyncio
import sys
import os

# ‡πÄ‡∏û‡∏¥‡πà‡∏° path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from tts_rvc_core import TTSRVCCore

async def test_multi_language():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö multi-language"""
    print("Testing Multi-Language TTS (Lao + English)...")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á core instance
    core = TTSRVCCore()
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤
    test_cases = [
        {
            "text": "‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ Hello ‡∫ó‡∫∏‡∫Å‡∫Ñ‡∫ª‡∫ô! How are you? ‡∫Ç‡ªâ‡∫≠‡∫ç‡∫î‡∫µ",
            "description": "Lao + English + Lao"
        },
        {
            "text": "Hello ‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ ‡∫ó‡∫∏‡∫Å‡∫Ñ‡∫ª‡∫ô! How are you today?",
            "description": "English + Lao + English"
        },
        {
            "text": "‡∫™‡∫∞‡∫ö‡∫≤‡∫ç‡∫î‡∫µ ‡∫ó‡∫∏‡∫Å‡∫Ñ‡∫ª‡∫ô! ‡∫Ç‡ªâ‡∫≠‡∫ç‡∫ä‡∫∑‡ªà‡∫ß‡ªà‡∫≤ John ‡ªÅ‡∫•‡∫∞ ‡∫Ç‡ªâ‡∫≠‡∫ç‡∫°‡∫≤‡∫à‡∫≤‡∫Å America",
            "description": "Lao + English + Lao"
        },
        {
            "text": "Welcome to ‡∫•‡∫≤‡∫ß! ‡∫õ‡∫∞‡ªÄ‡∫ó‡∫î‡∫ó‡∫µ‡ªà‡∫™‡∫ß‡∫ç‡∫á‡∫≤‡∫°",
            "description": "English + Lao"
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\\nTest {i}: {test_case['description']}")
        print(f"Text: {test_case['text']}")
        
        try:
            # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤
            segments = core.detect_language_segments(test_case['text'])
            print(f"Language detection: {len(segments)} segments")
            for j, (text, lang) in enumerate(segments):
                voice = core.get_voice_for_language(lang, 'lo-LA-KeomanyNeural')
                print(f"  Segment {j+1}: '{text}' -> {lang} ({voice})")
            
            # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            print("Generating audio...")
            audio_data = await core.generate_tts(
                test_case['text'], 
                'lo-LA-KeomanyNeural', 
                enable_multi_language=True
            )
            print(f"Audio generated: {len(audio_data)} bytes")
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            output_file = f"test_lao_english_{i}.wav"
            with open(output_file, 'wb') as f:
                f.write(audio_data)
            print(f"Saved: {output_file}")
            
        except Exception as e:
            print(f"Error: {e}")
    
    print("\\nTest completed!")

if __name__ == "__main__":
    asyncio.run(test_multi_language())
'''
    
    with open("test_lao_english.py", 'w', encoding='utf-8') as f:
        f.write(test_script)
    
    logger.info("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå test_lao_english.py")

def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å"""
    print("Fixing Multi-Language Detection for Lao + English...")
    
    # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô detect_language_segments
    if fix_tts_rvc_core():
        print("‚úÖ Fixed detect_language_segments function")
    else:
        print("‚ùå Failed to fix detect_language_segments function")
        return
    
    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô get_voice_for_language
    if update_get_voice_for_language():
        print("‚úÖ Updated get_voice_for_language function")
    else:
        print("‚ùå Failed to update get_voice_for_language function")
        return
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    create_test_script()
    
    print("\\nüéâ Multi-Language system fixed!")
    print("New features:")
    print("  - Detect English in Lao text")
    print("  - Use appropriate voice for each language")
    print("  - Merge adjacent segments with same language")
    print("  - Support Lao + English mixing")
    
    print("\\nTest the system:")
    print("  python test_lao_english.py")

if __name__ == "__main__":
    main() 